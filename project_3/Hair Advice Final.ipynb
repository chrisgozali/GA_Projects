{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9142e626",
   "metadata": {},
   "source": [
    "# Executive Summary and Problem Statement\n",
    "\n",
    "Stylescout.com is a website which provides advertising and appointment booking services for various hair salons in New York City. The website conducts extensive reviews on vairous salons and has several articles on their blog about the latest hair styles and trends. In this project, the primary stakeholder is stylescout.com and the secondary stakeholders are the people who use their website's services.\n",
    "\n",
    "I have been tasked by the creators of stylescout.com to build a classifier model using Natural Language Processing (NLP) and different machine learning techniques which can accurately predict language patterns that are related to male hairstyles or female hairstyles. They then intend to use this information to conduct search engine optimization to improve web traffic to articles and advertisements on their website which target one particular gender. Therefore, I have used posts from the subreddits 'r/femalehairadvice' and 'r/malehairadvice' to construct and test the models.\n",
    "\n",
    "5 classifier models were created which accurately predicted whether a post originates from either 'malehairadvice' or 'femalehairadvice' subreddits and each of the models' pros and cons were explored. The models were constructed using 1500 of the top posts from this year (2021) scraped from reddit.com and then evaluated using 500 new posts scraped a week later. Taking all this into consideration, the models were evaluated before 1 was recommended to stylescout.com for their search engine optimization algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb584959",
   "metadata": {},
   "source": [
    "# Contents\n",
    "- [Functions](#func)\n",
    "    * [Functions for Text Cleaning](#functxt)\n",
    "    * [Function for Gridsearch Cross Validation](#funcgs) \n",
    "    * [Function for searching Misclassified Documents](#funmisclass)\n",
    "- [Dataframe Checking](#data)\n",
    "- [Cleaning Text Data](#clean)\n",
    "- [Gridsearch Cross Validation](#gs)\n",
    "- [Pipelines](#pipe)\n",
    "    * [Pipeline 1 - Logistic Regression with Count Vectorizer](#p1)\n",
    "    * [Pipeline 2 - Logistic Regression with Tfidf Vectorizer](#p2)\n",
    "    * [Pipeline 3 - Naive Bayes Multinomial with Tfidf Vectorizer](#p3)\n",
    "    * [Pipeline 4 - Random Forest Classifier with Tfidf Vectorizer](#p4)\n",
    "    * [Pipeline 5 - Support Vector Classifier with Tfidf Vectorizer](#p5)\n",
    "- [Model Comparison](#compare)\n",
    "    * [Count Vectorizer vs Tfidf Vectorizer](#vec)\n",
    "    * [Models Evaluation](#eval)\n",
    "    * [Model Selected](#select)\n",
    "- [Conclusions and Recommendations](#conclude)\n",
    "    * [Model Limitations and Future Work](#future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc080d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "from numpy import random\n",
    "\n",
    "# Standard data science imports:\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords # Import the stopword list\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import  RandomForestClassifier#, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a603d06",
   "metadata": {},
   "source": [
    "<a id='func'></a>\n",
    "# Functions\n",
    "\n",
    "I created functions to shorten repetitive tasks such as text cleaning, gridsearch cross-validation and various document/corpus checks to ensure those tasks are performed identically. Click [here](#data) to jump to the pre-modelling process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e62e42a",
   "metadata": {},
   "source": [
    "<a id='functxt'></a>\n",
    "## Functions for text cleaning\n",
    "\n",
    "The functions below were used for cleaning the corpus by transforming the raw data into lemmatized and stemmed words. Certain strings were also removed as described in the function `text_to_words`. The functions were used in [Cleaning Text Data](#clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a78ba1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to check if word exists in a given corpus\n",
    "#Returns the document containing the word\n",
    "\n",
    "def word_checker(list_of_words, word):\n",
    "    result = []\n",
    "    for i in list_of_words:\n",
    "        if word in i:\n",
    "            result.append(i)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0af6de73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to check word pos tag\n",
    "#Input is a list of strings containing individual words\n",
    "#Returns the pos tag of the word in the format inputted into lemmatizer\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "487cd8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a raw document to a list of documents to be processed by each pipeline\n",
    "# The input is a single string, and \n",
    "# the output is a single string\n",
    "def text_to_words(raw_text):\n",
    "    \n",
    "    \n",
    "    # 1. Remove HTML.\n",
    "    document = BeautifulSoup(raw_text).get_text()\n",
    "    \n",
    "    # 2. Remove non-letters.\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", document)\n",
    "    \n",
    "    # 3. Convert to lower case, split into individual words.\n",
    "    words_list = letters_only.lower().split()\n",
    "    \n",
    "    #4. Select words from stopwords for removal\n",
    "    stops = set(['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves',\n",
    "                 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
    "                 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself',\n",
    "                 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "                 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those',\n",
    "                 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having',\n",
    "                 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as',\n",
    "                 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    "                 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from',\n",
    "                 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there',\n",
    "                 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other',\n",
    "                 'some', 'such', 'no', 'nor', 'only', 'own', 'same', 'so', 'than', 'too', 'very',\n",
    "                 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll',\n",
    "                 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\",\n",
    "                 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\",\n",
    "                 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn',\n",
    "                 \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"])\n",
    "    #Words related to the subreddit and website were removed\n",
    "    #Words directly indicating gender such as 'male' or 'female' were removed\n",
    "    #'haircut' and 'hairstyle' were removed as they are common and do not connote a particular gender\n",
    "    #'like' was removed as it was a commonly used term and also does not connote a particular gender. \n",
    "    #Furthermore, the meaning of 'like' changes depending on the context it is used\n",
    "    removed_words = set(['www','http','com','woman','man','female','male','hair','advice','went','want','get',\n",
    "                         'malehairadvice','femalehairadvice','reddit','haircut','hairstyle','style',\n",
    "                         'like','likes','liked','liking'])\n",
    "    \n",
    "    # 5. Remove words manually.\n",
    "    meaningful_words = [w for w in words_list if w not in stops]\n",
    "    meaningful_words2 = [w for w in meaningful_words if w not in removed_words]\n",
    "    \n",
    "    #6. WordNet lemmatizer\n",
    "    tags = nltk.pos_tag(meaningful_words2)\n",
    "    wordnet_tagged = map(lambda x: (x[0], get_wordnet_pos(x[1])), tags)\n",
    "\n",
    "    meaningful_words3 = [lemmatizer.lemmatize(word, pos = tag) if tag !='' else lemmatizer.lemmatize(word) for word, tag in wordnet_tagged ]\n",
    "    \n",
    "    # 7. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return(\" \".join(meaningful_words3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55b2b02",
   "metadata": {},
   "source": [
    "Most of the words from the default english stopwords library were used. The cell below denotes which words were excluded from cleaning in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f1fb3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do\n",
      "up\n",
      "down\n",
      "in\n",
      "out\n",
      "on\n",
      "off\n",
      "not\n"
     ]
    }
   ],
   "source": [
    "#replicate the stopwords selected in the function above\n",
    "stops = set(['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves',\n",
    "                 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
    "                 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself',\n",
    "                 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "                 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those',\n",
    "                 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having',\n",
    "                 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as',\n",
    "                 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    "                 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from',\n",
    "                 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there',\n",
    "                 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other',\n",
    "                 'some', 'such', 'no', 'nor', 'only', 'own', 'same', 'so', 'than', 'too', 'very',\n",
    "                 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll',\n",
    "                 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\",\n",
    "                 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\",\n",
    "                 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn',\n",
    "                 \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"])\n",
    "\n",
    "#The following words were not excluded from the default stopwords\n",
    "for w in stopwords.words('english'):\n",
    "    if w not in stops:\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc413c79",
   "metadata": {},
   "source": [
    "<a id='funcgs'></a>\n",
    "## Function for GridsearchCV\n",
    "\n",
    "The function below contains the function used for gridsearch. This was used in [Gridsearch Cross Validation](#gs) to optimize the hyperparameters for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "178ab6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function which performs gridsearching over different pipelines\n",
    "#inputs are lists containing the vectorizers, models and respective parameters for each pipeline\n",
    "#outputs are lists containing the cross validated score and best parameters for each pipeline\n",
    "\n",
    "def gridsearcher(vectorizer,model,parameters,X,y):\n",
    "    cross_val_scores = []\n",
    "    best_params = []\n",
    "    cvec = CountVectorizer()\n",
    "    tvec = TfidfVectorizer()\n",
    "    log_reg = LogisticRegression(random_state = 25)\n",
    "    nb = MultinomialNB()\n",
    "    rf = RandomForestClassifier(random_state = 25)\n",
    "    svc = SVC(random_state = 25)\n",
    "    \n",
    "    for n, p in enumerate(parameters):\n",
    "        pipe = Pipeline([('vec', vectorizer[n]),\n",
    "                         ('model', model[n])])\n",
    "        gs = GridSearchCV(pipe,\n",
    "                         param_grid = parameters[n],\n",
    "                         cv = 5)\n",
    "        gs.fit(X,y)\n",
    "        cross_val_scores.append(gs.best_score_)\n",
    "        best_params.append(gs.best_params_)\n",
    "    return cross_val_scores, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aec14f2",
   "metadata": {},
   "source": [
    "<a id='funmisclass'></a>\n",
    "## Function for checking misclassified documents\n",
    "This function was used to search for misclassified documents for each model for the purpose of [evaluation](#eval) of the different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22725f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function which searches the corpus for misclassifications for a particular model\n",
    "#Inputs are the dataset, true class values and pipeline\n",
    "#Outputs are lists of the false positives and false negatives separately along with their original and cleaned documents and probabilities\n",
    "\n",
    "def misclassifier(X, y_true, pipeline):\n",
    "    \n",
    "    #Make predictions\n",
    "    preds = pipeline.predict(X)\n",
    "    \n",
    "    #Get indices of the misclassified datapoints\n",
    "    indices = [i for i in range(len(y_true)) if y_true.iloc[i] != preds[i]]\n",
    "    \n",
    "    #Get text for lemmatized + stemmed documents\n",
    "    corpus = pd.DataFrame(data = {'Cleaned Documents':[text_to_words(doc) for doc in X],\n",
    "                                  'Original Documents':[doc for doc in X]},\n",
    "                          index = [X.index])\n",
    "    \n",
    "    #Get only the misclassified text\n",
    "    false_predictions = corpus.iloc[indices]\n",
    "    \n",
    "    #Get the misclassification results\n",
    "    false_pred_classes = [preds[i] for i in range(len(y_true)) if y_true.iloc[i] != preds[i]]\n",
    "    \n",
    "    #summarize misclassified text as DataFrame\n",
    "    misclassified = false_predictions\n",
    "    misclassified.loc[:,'Predicted Class'] = false_pred_classes\n",
    "    \n",
    "    #Separate misclassifications by false positives or false negatives\n",
    "    misclassified_as_female = misclassified[misclassified.loc[:,'Predicted Class'] ==1]\n",
    "    misclassified_as_male = misclassified[misclassified.loc[:,'Predicted Class'] ==0]\n",
    "    \n",
    "    #Add the probabilities that led to each false prediction\n",
    "    misclassified_as_female.loc[:,'Probability Female'] = pipeline.predict_proba(misclassified_as_female.loc[:,'Original Documents'])[:,1]\n",
    "    misclassified_as_male.loc[:,'Probability Male'] = pipeline.predict_proba(misclassified_as_male.loc[:,'Original Documents'])[:,0]\n",
    "    \n",
    "    return misclassified_as_female, misclassified_as_male"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fce409",
   "metadata": {},
   "source": [
    "<a id='data'></a>\n",
    "# Dataframe Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fd382f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframes\n",
    "\n",
    "male_df = pd.read_csv('./malehairadvice.csv')\n",
    "female_df = pd.read_csv('./femalehairadvice.csv')\n",
    "\n",
    "#Load unseen data for model evaluation\n",
    "unseen_male = pd.read_csv('./malehairadvice_unseen.csv')\n",
    "unseen_female = pd.read_csv('./femalehairadvice_unseen.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41994432",
   "metadata": {},
   "source": [
    "Another set of dataframes was scraped using 'new' posts on the respective subreddits to provide a larger testing set to evaluate the models. This is thereafter referred to the unseen dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acd83984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change setting so we can read the entire document for each row\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df96a975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(989, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64064cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(996, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a2ef889",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Post-Quarantine: Shaved My Head. Thoughts?</td>\n",
       "      <td>malehairadvice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Take notes, boys.</td>\n",
       "      <td>malehairadvice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Before and after: Covid Cut</td>\n",
       "      <td>malehairadvice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How did I do boys?</td>\n",
       "      <td>malehairadvice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A good way to remember how to correctly place toilet paper</td>\n",
       "      <td>malehairadvice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         text       subreddit\n",
       "0                  Post-Quarantine: Shaved My Head. Thoughts?  malehairadvice\n",
       "1                                           Take notes, boys.  malehairadvice\n",
       "2                                 Before and after: Covid Cut  malehairadvice\n",
       "3                                          How did I do boys?  malehairadvice\n",
       "4  A good way to remember how to correctly place toilet paper  malehairadvice"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7701b01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[UPDATE!] Thank you to everyone who took the time to comment on my shag when I was feeling unsure. I changed up my glasses and styled it with curtain bangs instead and I am in LOVE with the way it looks now!!</td>\n",
       "      <td>femalehairadvice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asked advice yesterday, followed said advice and am loving the result!</td>\n",
       "      <td>femalehairadvice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Update: I'm the trans girl from last week, I took the advice and got the bangs/eyebrow trim!</td>\n",
       "      <td>femalehairadvice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Finally made the chop! Before &amp;amp; after</td>\n",
       "      <td>femalehairadvice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Took some advice, left some out. Went in for a chop at couldn’t be happier</td>\n",
       "      <td>femalehairadvice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                               text  \\\n",
       "0  [UPDATE!] Thank you to everyone who took the time to comment on my shag when I was feeling unsure. I changed up my glasses and styled it with curtain bangs instead and I am in LOVE with the way it looks now!!   \n",
       "1                                                                                                                                            Asked advice yesterday, followed said advice and am loving the result!   \n",
       "2                                                                                                                      Update: I'm the trans girl from last week, I took the advice and got the bangs/eyebrow trim!   \n",
       "3                                                                                                                                                                         Finally made the chop! Before &amp; after   \n",
       "4                                                                                                                                        Took some advice, left some out. Went in for a chop at couldn’t be happier   \n",
       "\n",
       "          subreddit  \n",
       "0  femalehairadvice  \n",
       "1  femalehairadvice  \n",
       "2  femalehairadvice  \n",
       "3  femalehairadvice  \n",
       "4  femalehairadvice  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890eac1f",
   "metadata": {},
   "source": [
    "The imported dataframes for each respective subreddit contain a similar number of documents.\n",
    "\n",
    "As this is a classification problem involving two classes, we assign the numbers 1 and 0 to each class. In this case, posts belonging to the subreddit r/femalehairadvice are assigned as class 1. On the other hand, posts belonging to subreddit r/malehairadvice are assigned as class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9607bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine subreddits and reset indices.\n",
    "df_raw = pd.concat([male_df,female_df]).drop_duplicates().reset_index(drop = True)\n",
    "unseen_raw = pd.concat([unseen_male,unseen_female]).drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e4e7c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle rows for unseen dataframe\n",
    "unseen_raw = unseen_raw.sample(frac=1, random_state = 25).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20089902",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Posts from r/femalehairadvice are denoted as class 1, from r/malehairadvice are denoted as class 0\n",
    "target_dict = {'femalehairadvice': 1, 'malehairadvice': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f08960a",
   "metadata": {},
   "source": [
    "**Note:** The secondary stakeholders are largely female, therefore r/femalehairadvice was set as class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34f6c61d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Mapping the target variable.\n",
    "df_raw['subreddit'] = df_raw['subreddit'].map(target_dict)\n",
    "unseen_raw['subreddit'] = unseen_raw['subreddit'].map(target_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00acfe8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Post-Quarantine: Shaved My Head. Thoughts?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Take notes, boys.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Before and after: Covid Cut</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How did I do boys?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A good way to remember how to correctly place toilet paper</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>Hi! I need your help. I decided to change my blond (second photo) to my original dark brown color. But my hair still tries to come back to the blonde color (first photo). Can you please recommend any good products with a brown coloring effect?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>Hair’s getting gray and unruly and mostly refuses to straighten (even with a CHI and products). HALP. Can I pull off a singer-known-as-Pink hairstyle with my big ol’ head?? Any other suggestions besides?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>Would a pixie cut suit me?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>Okay so the first picture is of my hair. I want to change it up a bit but I'm afraid if I cut it shoulder length(like the rest of the pictures), it will be unruly and undefined. I wanna keep it low-maintenance(this includes no heat and without many products) do you think this style would suit me?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>Hey gang! Sorry for the bad photo, the only one I have that shows my hair! Could I pull off dying my hair black? I'm so tired of blue!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1985 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                           text  \\\n",
       "0                                                                                                                                                                                                                                                                    Post-Quarantine: Shaved My Head. Thoughts?   \n",
       "1                                                                                                                                                                                                                                                                                             Take notes, boys.   \n",
       "2                                                                                                                                                                                                                                                                                   Before and after: Covid Cut   \n",
       "3                                                                                                                                                                                                                                                                                            How did I do boys?   \n",
       "4                                                                                                                                                                                                                                                    A good way to remember how to correctly place toilet paper   \n",
       "...                                                                                                                                                                                                                                                                                                         ...   \n",
       "1980                                                        Hi! I need your help. I decided to change my blond (second photo) to my original dark brown color. But my hair still tries to come back to the blonde color (first photo). Can you please recommend any good products with a brown coloring effect?   \n",
       "1981                                                                                                Hair’s getting gray and unruly and mostly refuses to straighten (even with a CHI and products). HALP. Can I pull off a singer-known-as-Pink hairstyle with my big ol’ head?? Any other suggestions besides?   \n",
       "1982                                                                                                                                                                                                                                                                                 Would a pixie cut suit me?   \n",
       "1983  Okay so the first picture is of my hair. I want to change it up a bit but I'm afraid if I cut it shoulder length(like the rest of the pictures), it will be unruly and undefined. I wanna keep it low-maintenance(this includes no heat and without many products) do you think this style would suit me?   \n",
       "1984                                                                                                                                                                    Hey gang! Sorry for the bad photo, the only one I have that shows my hair! Could I pull off dying my hair black? I'm so tired of blue!!   \n",
       "\n",
       "      subreddit  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "...         ...  \n",
       "1980          1  \n",
       "1981          1  \n",
       "1982          1  \n",
       "1983          1  \n",
       "1984          1  \n",
       "\n",
       "[1985 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6177316a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.501763\n",
       "0    0.498237\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline score\n",
    "df_raw['subreddit'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57019d96",
   "metadata": {},
   "source": [
    "Our baseline score is 50.2%. This is the accuracy to beat to know that our model works in predicting the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f48ae6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.501002\n",
       "0    0.498998\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the class distribution in the unseen dataset\n",
    "unseen_raw['subreddit'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28b67f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e23caf3",
   "metadata": {},
   "source": [
    "The unseen dataset contains 500 documents and is of a similar class distribution compared to the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd211fbc",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "# Cleaning Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1409e91",
   "metadata": {},
   "source": [
    "\n",
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30fdbeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_raw['text'],\n",
    "                                                    df_raw['subreddit'],\n",
    "                                                    test_size = 0.25,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b3a30dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5040322580645161"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the class distribution of our training set\n",
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33f6ee43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4949698189134809"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the class distribution of our test set\n",
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3931a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate wordnet lemmatizer and porter stemmer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "p_stemmer= PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "523821b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to hold the clean text\n",
    "train_clean = []\n",
    "test_clean = []\n",
    "\n",
    "# For every document in our training set\n",
    "for train_text in X_train:\n",
    "    \n",
    "    # Process documents using function then append to train_clean.\n",
    "    train_clean.append(text_to_words(train_text))\n",
    "    \n",
    "\n",
    "# For every document in our testing set\n",
    "for test_text in X_test:\n",
    "    #Process documents using function then append to test_clean.\n",
    "    test_clean.append(text_to_words(test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbce50d",
   "metadata": {},
   "source": [
    "I used [this function](#funclean) to clean the text data. \n",
    "\n",
    "Both lemmatization and stemming were used sequentially. This ensured that all words were lemmatized then converted to their respective stems, reducing the variety of the different forms of words.\n",
    "\n",
    "Specific words removed included words that directly associated with the subreddit names such as 'male', 'female', 'hair' and 'advice'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6c88acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform the same text cleaning process to the unseen dataset\n",
    "X_unseen = unseen_raw[['text']]\n",
    "y_unseen = unseen_raw['subreddit']\n",
    "\n",
    "unseen_clean = []\n",
    "for unseen_text in X_unseen['text']:\n",
    "    unseen_clean.append(text_to_words(unseen_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a146fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do brown brown little orange undertone',\n",
       " 'frizzy medium thick asian rarely use heat damp brush out apply oil use garnier in shampoo conditioner use use tresemme use do tame',\n",
       " 'get first time in year thank guy',\n",
       " 'short long right currently cut short time without bang',\n",
       " 'beard think general consensus beard good kinda really wild top center vibe still hear always generally right hot not mild wild',\n",
       " 'unsure bang not on washday feeling lose bit bored',\n",
       " 'hi guy think get bang know type bang would best fit face shape naturally curly',\n",
       " 'try grow out see itd look good didnt straight floppy poof out alot on side hoe cut look less weird',\n",
       " 'recently start miss natural color nd picture color exactly color want in begin mess around purple shampoo bit take little bit orangeness still think something miss perfect',\n",
       " 'really large ear need suggestion look good']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check how the cleaned data looks like\n",
    "train_clean[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94c1f634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['please help even leave house without hat anymore hairline atrocious make fun life detail in comment',\n",
       " 'take subreddit cut shorter get bang thank',\n",
       " 'inspire short ever gain new confidence also able reach goal inch go princess trust charity',\n",
       " 'uhh cut bang know leave another please help',\n",
       " 'anyway fix subhuman appearance bald good picture',\n",
       " 'think go bald rest in peace lol',\n",
       " 'idea',\n",
       " 'tomorrow graduation picture recommendation shave facial',\n",
       " 'current length bit product leave in last night gonna keep grow out style look in',\n",
       " 'month definitely need fix']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clean[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d543f33c",
   "metadata": {},
   "source": [
    "<a id='gs'></a>\n",
    "# Gridsearch Cross Validation\n",
    "\n",
    "Several iterations of gridsearch cross validation were performed using various models and hyperparameters. The cells below contain a narrowed down set of models during the final iterations of gridsearch. Other models that were tested and excluded from this set due to overfitting are:\n",
    "    - K nearest neighbors classifier\n",
    "    - Decision tree classifier\n",
    "    - Bagging classifier\n",
    "    - Adaptive boost classifier\n",
    "The above models were crossed out due to having significantly lower test accuracy scores as compared to their training accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc442f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate vectorizers\n",
    "cvec = CountVectorizer()\n",
    "tvec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "806507da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of vectorizers used in gridsearch\n",
    "vectorizers_list = [cvec,\n",
    "                    tvec,\n",
    "                    tvec,\n",
    "                    tvec,\n",
    "                    tvec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43fa811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate models\n",
    "log_reg = LogisticRegression(random_state = 25)\n",
    "nb = MultinomialNB()\n",
    "rf = RandomForestClassifier(random_state = 25)\n",
    "svc = SVC(random_state = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c82a2a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of models used in gridsearch\n",
    "models_list = [log_reg,\n",
    "               log_reg,\n",
    "               nb,\n",
    "               rf,\n",
    "               svc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053b1771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters used for each respective pipeline.\n",
    "\n",
    "#Each pipeline contains 1 vectorizer and 1 model.\n",
    "\n",
    "params_list = [{'vec__max_features': [400,500,600],# First pipeline countvectorizer, logisticregression\n",
    "               'vec__min_df': [3,4,5],\n",
    "               'vec__max_df': [0.15,0.2,0.25],\n",
    "               'vec__stop_words' : [None,'english'],\n",
    "               'vec__ngram_range': [(1,1),(1,2)],\n",
    "               'model__C': [0.1,1,10],\n",
    "               'model__max_iter': [500]},\n",
    "              {'vec__max_features': [1100,1200,1300],#Second pipeline tfidfvectorizer, logisticregression\n",
    "               'vec__min_df': [1,2,3],\n",
    "               'vec__max_df': [0.05,0.1,0.15],\n",
    "               'vec__stop_words' : [None,'english'],\n",
    "               'vec__ngram_range': [(1,1),(1,2)],\n",
    "               'model__C': [0.1,1,10],\n",
    "               'model__max_iter': [1000]},\n",
    "              {'vec__max_features': [500,600,700],#Third pipeline tfidfvectorizer, Naive bayes multinomial\n",
    "               'vec__min_df': [2,3,4],\n",
    "               'vec__max_df': [0.05,0.1,0.15],\n",
    "               'vec__stop_words' : [None,'english'],\n",
    "               'vec__ngram_range': [(1,1),(1,2)],\n",
    "               'model__alpha': [0.6,0.7,0.8],\n",
    "               'model__fit_prior': [True,False]},\n",
    "              {'vec__max_features': [2100,2200,2300],#Fourth pipeline tfidfvectorizer, RandomForestClassifier\n",
    "               'vec__min_df': [1,2,3],\n",
    "               'vec__max_df': [0.05,0.1,0.15,0.2],\n",
    "               'vec__stop_words' : [None,'english'],\n",
    "               'vec__ngram_range': [(1,1),(1,2)],\n",
    "               'model__criterion': ['gini','entropy'],\n",
    "               'model__max_depth': [10,20,30],\n",
    "               'model__n_estimators': [100,150,200,250]},\n",
    "              {'vec__max_features': [2100,2200,2300],#Fith pipeline tfidfvectorizer, supportvectorclassifier\n",
    "               'vec__min_df': [1,2,3],\n",
    "               'vec__max_df': [0.05,0.1,0.15],\n",
    "               'vec__stop_words' : ['english'],\n",
    "               'vec__ngram_range': [(1,1),(1,2)],\n",
    "               'model__C': [0.3,0.4,0.5],\n",
    "               'model__kernel' : ['rbf','linear','poly'],\n",
    "               'model__degree': [1,2,3],\n",
    "               'model__gamma': ['scale']}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e9a9df",
   "metadata": {},
   "source": [
    "Refer to [Function for Gridsearch Cross Validation](#funcgs) for function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "693c37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_scores, best_params = gridsearcher(vectorizer = vectorizers_list,\n",
    "                                             model = models_list,\n",
    "                                             parameters = params_list,\n",
    "                                             X = X_train,\n",
    "                                             y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cbf41d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8038031319910515,\n",
       " 0.8138725058188145,\n",
       " 0.8286556843603824,\n",
       " 0.7937134205590582,\n",
       " 0.8172417689196214]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d8ba65",
   "metadata": {},
   "source": [
    "We have achieved cross validation scores of about 80% - 82% for our selected models. All of them beat the baseline accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "15dd4fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model__C': 0.1,\n",
       "  'model__max_iter': 500,\n",
       "  'vec__max_df': 0.2,\n",
       "  'vec__max_features': 500,\n",
       "  'vec__min_df': 4,\n",
       "  'vec__ngram_range': (1, 1),\n",
       "  'vec__stop_words': 'english'},\n",
       " {'model__C': 1,\n",
       "  'model__max_iter': 1000,\n",
       "  'vec__max_df': 0.1,\n",
       "  'vec__max_features': 1200,\n",
       "  'vec__min_df': 1,\n",
       "  'vec__ngram_range': (1, 1),\n",
       "  'vec__stop_words': 'english'},\n",
       " {'model__alpha': 0.7,\n",
       "  'model__fit_prior': False,\n",
       "  'vec__max_df': 0.15,\n",
       "  'vec__max_features': 700,\n",
       "  'vec__min_df': 3,\n",
       "  'vec__ngram_range': (1, 1),\n",
       "  'vec__stop_words': 'english'},\n",
       " {'model__criterion': 'gini',\n",
       "  'model__max_depth': 20,\n",
       "  'model__n_estimators': 200,\n",
       "  'vec__max_df': 0.15,\n",
       "  'vec__max_features': 2300,\n",
       "  'vec__min_df': 1,\n",
       "  'vec__ngram_range': (1, 1),\n",
       "  'vec__stop_words': 'english'},\n",
       " {'model__C': 0.4,\n",
       "  'model__degree': 1,\n",
       "  'model__gamma': 'scale',\n",
       "  'model__kernel': 'rbf',\n",
       "  'vec__max_df': 0.1,\n",
       "  'vec__max_features': 2200,\n",
       "  'vec__min_df': 1,\n",
       "  'vec__ngram_range': (1, 1),\n",
       "  'vec__stop_words': 'english'}]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1e3596",
   "metadata": {},
   "source": [
    "<a id='pipe'></a>\n",
    "# Pipelines\n",
    "This section contains the different pipelines for the models and some exploration into their results. The parameters for each pipeline were set using the best parameters found during the gridsearch. The results for the models are discussed in depth in the [Model Comparison](#compare) section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb48b9c",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "The logistic regression model is a commonly used binary classifier and is used in pipelines 1 and 2. It assumes a linear relationship between features and the log-odds of class = 1.\n",
    "\n",
    "To interpret the intercept and coefficients of the model, we need to first exponentiate the values. The result is interpreted as odds. For the exponentiated intercept, it is the likelihood of predicting class 1 as opposed to class 0 when the other predictors are = 0. For coefficients, the sign represents whether the feature increases or decreases the odds of predicting class 1. The magnitude of the exponentiated coefficient represents an increase in likelihood of predicting class 1 (or class 0 for negative coefficients)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3878bbb4",
   "metadata": {},
   "source": [
    "<a id='p1'></a>\n",
    "## Pipe 1 - Logistic Regression with Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7396aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate pipeline\n",
    "pipe1 = Pipeline([\n",
    "    ('vec', CountVectorizer()),\n",
    "    ('model', LogisticRegression(random_state = 25))\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ad35185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__C': 0.1,\n",
       " 'model__max_iter': 500,\n",
       " 'vec__max_df': 0.2,\n",
       " 'vec__max_features': 500,\n",
       " 'vec__min_df': 4,\n",
       " 'vec__ngram_range': (1, 1),\n",
       " 'vec__stop_words': 'english'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the best parameters found during gridsearch\n",
    "best_params[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de0d1d8",
   "metadata": {},
   "source": [
    "Note that the regularization parameter C was set as 0.1 when the default value is 1. A smaller number such as in this case indicates stronger regularization. Regularization imposes a penalty of the coefficients of the model to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56ebd903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vec',\n",
       "                 CountVectorizer(max_df=0.2, max_features=500, min_df=4,\n",
       "                                 stop_words='english')),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=0.1, max_iter=500, random_state=25))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set parameters accordingly and fit to training set\n",
    "pipe1.set_params(model__C = 0.1,\n",
    "                model__max_iter = 500,\n",
    "                vec__max_df = 0.2,\n",
    "                vec__max_features = 500,\n",
    "                vec__min_df = 4,\n",
    "                vec__ngram_range = (1, 1),\n",
    "                vec__stop_words = 'english')\n",
    "\n",
    "pipe1.fit(train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a86e1874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store train and test accuracy scores for comparison later\n",
    "log_reg_count_train_score = pipe1.score(train_clean,y_train)\n",
    "log_reg_count_test_score = pipe1.score(test_clean,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "17cb955d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Logistic Regression with Count Vectorization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Confusion Matrix for Logistic Regression with Count Vectorization')\n",
    "plot_confusion_matrix(pipe1,test_clean,y_test, cmap = 'Blues');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289930cd",
   "metadata": {},
   "source": [
    "**Observation:** There much more false negatives than there are false positives.\n",
    "False negatives are posts that were predicted to be from r/malehairadvice but were actually from r/femalehairadvice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ad257d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1597: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1597: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "#Store misclassified documents for comparison later\n",
    "misclassified_as_female1, misclassified_as_male1 = misclassifier(X = X_test,\n",
    "                                                               y_true = y_test,\n",
    "                                                               pipeline = pipe1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8649ab11",
   "metadata": {},
   "source": [
    "### Interpreting Intercept and Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c293697",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60727381])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get intercept for the logistic regression model\n",
    "np.exp(pipe1['model'].intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86b9763",
   "metadata": {},
   "source": [
    "The exponentiated intercept represents a 0.607 increase in predicting r/femalehairadvice when the document contains no predictive features. This ties in with having more false negatives than false positives. The intercept may account for shorter documents with weak predictive features which were then misclassified to be from r/malehairadvice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b4341a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get coefficients for the logistic regression model\n",
    "features1 = pipe1['vec'].get_feature_names()\n",
    "coefficients1 = pipe1['model'].coef_\n",
    "coef_df1 = pd.DataFrame(coefficients1,columns = features1).T\n",
    "coef_df1.rename(columns = {0:'Coefficient'}, inplace = True)\n",
    "coef_df1['Increase in odds'] = np.exp(coef_df1.loc[:,'Coefficient'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5066054",
   "metadata": {},
   "source": [
    "The sign of the coefficient for logistic regression tells us whether the feature predicts r/femalehairadvice(positive) or r/malehairadvice(negative).\n",
    "The coefficients themselves can be interpreted by exponentiating their values. The result represents an increase in odds of predicting r/femalehairadvice.\n",
    "\n",
    "The following are the top 10 features which in predicting posts from r/femalehairadvice subreddit and r/malehairadvice subreddit respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4d71770",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Increase in odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bang</th>\n",
       "      <td>1.719675</td>\n",
       "      <td>5.582716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color</th>\n",
       "      <td>1.304319</td>\n",
       "      <td>3.685177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pixie</th>\n",
       "      <td>0.850779</td>\n",
       "      <td>2.341470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.789800</td>\n",
       "      <td>2.202955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bob</th>\n",
       "      <td>0.683290</td>\n",
       "      <td>1.980382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colour</th>\n",
       "      <td>0.653258</td>\n",
       "      <td>1.921793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chop</th>\n",
       "      <td>0.627223</td>\n",
       "      <td>1.872404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blonde</th>\n",
       "      <td>0.599795</td>\n",
       "      <td>1.821745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>update</th>\n",
       "      <td>0.574431</td>\n",
       "      <td>1.776120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thank</th>\n",
       "      <td>0.560106</td>\n",
       "      <td>1.750858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Coefficient  Increase in odds\n",
       "bang       1.719675          5.582716\n",
       "color      1.304319          3.685177\n",
       "pixie      0.850779          2.341470\n",
       "love       0.789800          2.202955\n",
       "bob        0.683290          1.980382\n",
       "colour     0.653258          1.921793\n",
       "chop       0.627223          1.872404\n",
       "blonde     0.599795          1.821745\n",
       "update     0.574431          1.776120\n",
       "thank      0.560106          1.750858"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 10 features predicting femalehairadvice\n",
    "coef_df1.sort_values(by = 'Coefficient', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b19a1",
   "metadata": {},
   "source": [
    "The top feature is the word 'bang' which increases the odds of predicting r/femalehairadvice by 5.58 times.\n",
    "**Observation:**\n",
    "Strong predictive features include popular terms that describe female hairstyles such as 'bang', 'pixie', 'bob'\n",
    "and hair colour 'color','colour','blond'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d028b80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Increase in odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>barber</th>\n",
       "      <td>-0.810460</td>\n",
       "      <td>0.444654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beard</th>\n",
       "      <td>-0.743460</td>\n",
       "      <td>0.475466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recede</th>\n",
       "      <td>-0.439306</td>\n",
       "      <td>0.644483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guy</th>\n",
       "      <td>-0.425163</td>\n",
       "      <td>0.653663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hairline</th>\n",
       "      <td>-0.404280</td>\n",
       "      <td>0.667457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grow</th>\n",
       "      <td>-0.391789</td>\n",
       "      <td>0.675847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longer</th>\n",
       "      <td>-0.381856</td>\n",
       "      <td>0.682593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buzz</th>\n",
       "      <td>-0.359191</td>\n",
       "      <td>0.698241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>-0.327748</td>\n",
       "      <td>0.720545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usually</th>\n",
       "      <td>-0.325110</td>\n",
       "      <td>0.722448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Coefficient  Increase in odds\n",
       "barber      -0.810460          0.444654\n",
       "beard       -0.743460          0.475466\n",
       "recede      -0.439306          0.644483\n",
       "guy         -0.425163          0.653663\n",
       "hairline    -0.404280          0.667457\n",
       "grow        -0.391789          0.675847\n",
       "longer      -0.381856          0.682593\n",
       "buzz        -0.359191          0.698241\n",
       "know        -0.327748          0.720545\n",
       "usually     -0.325110          0.722448"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top10 features predicting malehairadvice\n",
    "coef_df1.sort_values(by = 'Coefficient', ascending = True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8d0039",
   "metadata": {},
   "source": [
    "The top feature 'barber' changes the odds of predicting r/femalehairadvice by 0.445 times.\n",
    "**Observation:** Men tend to be concerned with receding hairlines. Features such as 'beard' are strongly associated with men. Men also tend to refer to hairstylists as 'barber'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc951a3",
   "metadata": {},
   "source": [
    "<a id='p2'></a>\n",
    "## Pipe 2 -  Logistic Regression with Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0752ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate pipeline\n",
    "pipe2 = Pipeline([\n",
    "    ('vec', TfidfVectorizer()),\n",
    "    ('model', LogisticRegression(random_state = 25))\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df9879ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__C': 1,\n",
       " 'model__max_iter': 1000,\n",
       " 'vec__max_df': 0.1,\n",
       " 'vec__max_features': 1200,\n",
       " 'vec__min_df': 1,\n",
       " 'vec__ngram_range': (1, 1),\n",
       " 'vec__stop_words': 'english'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check best parameters found during gridsearch\n",
    "best_params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4df65ee6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vec',\n",
       "                 TfidfVectorizer(max_df=0.1, max_features=1200,\n",
       "                                 stop_words='english')),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=1, max_iter=1000, random_state=25))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set parameters accordingly and fit to train dataset\n",
    "pipe2.set_params(model__C= 1,\n",
    "                 model__max_iter= 1000,\n",
    "                 vec__max_df= 0.1,\n",
    "                 vec__max_features= 1200,\n",
    "                 vec__min_df= 1,\n",
    "                 vec__ngram_range= (1, 1),\n",
    "                 vec__stop_words= 'english')\n",
    "\n",
    "pipe2.fit(train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dfda80f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store train and test accuracy scores for comparison later\n",
    "log_reg_tfidf_train_score = pipe2.score(train_clean, y_train)\n",
    "log_reg_tfidf_test_score = pipe2.score(test_clean, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "358ac648",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Logistic Regression with Tfidf Vectorization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Confusion Matrix for Logistic Regression with Tfidf Vectorization')\n",
    "plot_confusion_matrix(pipe2,test_clean,y_test, cmap = 'Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aa044b2f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1597: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1597: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "#Store misclassified documents for comparison later\n",
    "misclassified_as_female2, misclassified_as_male2 = misclassifier(X = X_test,\n",
    "                                                               y_true = y_test,\n",
    "                                                               pipeline = pipe2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f339204e",
   "metadata": {},
   "source": [
    "### Interpreting intercept and coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c959c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62064861])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get intercept for logistic regression mdoel\n",
    "np.exp(pipe2['model'].intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0688bf07",
   "metadata": {},
   "source": [
    "The exponentiated intercept represents a 0.657 increase in predicting r/femalehairadvice when the document contains no predictive features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3ef72a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get coefficients for the logistic regression model\n",
    "features2 = pipe2['vec'].get_feature_names()\n",
    "coefficients2 = pipe2['model'].coef_\n",
    "coef_df2 = pd.DataFrame(coefficients2,columns = features2).T\n",
    "coef_df2.rename(columns = {0:'Coefficient'}, inplace = True)\n",
    "coef_df2['Increase in odds'] = np.exp(coef_df2.loc[:,'Coefficient'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0b0ee2",
   "metadata": {},
   "source": [
    "The following are the top 10 features which in predicting posts from r/femalehairadvice subreddit and r/malehairadvice subreddit respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6eb53c07",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Increase in odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bang</th>\n",
       "      <td>5.186504</td>\n",
       "      <td>178.842242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color</th>\n",
       "      <td>3.972480</td>\n",
       "      <td>53.116093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>2.640218</td>\n",
       "      <td>14.016261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pixie</th>\n",
       "      <td>2.623608</td>\n",
       "      <td>13.785371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colour</th>\n",
       "      <td>2.281447</td>\n",
       "      <td>9.790838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blonde</th>\n",
       "      <td>2.086993</td>\n",
       "      <td>8.060637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bob</th>\n",
       "      <td>2.063674</td>\n",
       "      <td>7.874848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chop</th>\n",
       "      <td>1.697612</td>\n",
       "      <td>5.460894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dye</th>\n",
       "      <td>1.688176</td>\n",
       "      <td>5.409604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red</th>\n",
       "      <td>1.664538</td>\n",
       "      <td>5.283231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Coefficient  Increase in odds\n",
       "bang       5.186504        178.842242\n",
       "color      3.972480         53.116093\n",
       "love       2.640218         14.016261\n",
       "pixie      2.623608         13.785371\n",
       "colour     2.281447          9.790838\n",
       "blonde     2.086993          8.060637\n",
       "bob        2.063674          7.874848\n",
       "chop       1.697612          5.460894\n",
       "dye        1.688176          5.409604\n",
       "red        1.664538          5.283231"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df2.sort_values(by = 'Coefficient', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b724c50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Increase in odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>barber</th>\n",
       "      <td>-2.467369</td>\n",
       "      <td>0.084808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beard</th>\n",
       "      <td>-2.378340</td>\n",
       "      <td>0.092704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recede</th>\n",
       "      <td>-1.444641</td>\n",
       "      <td>0.235831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longer</th>\n",
       "      <td>-1.367526</td>\n",
       "      <td>0.254736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hairline</th>\n",
       "      <td>-1.314167</td>\n",
       "      <td>0.268698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>-1.197686</td>\n",
       "      <td>0.301892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usually</th>\n",
       "      <td>-1.093983</td>\n",
       "      <td>0.334880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>style</th>\n",
       "      <td>-1.055730</td>\n",
       "      <td>0.347938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buzz</th>\n",
       "      <td>-1.051656</td>\n",
       "      <td>0.349359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bald</th>\n",
       "      <td>-1.022986</td>\n",
       "      <td>0.359520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Coefficient  Increase in odds\n",
       "barber      -2.467369          0.084808\n",
       "beard       -2.378340          0.092704\n",
       "recede      -1.444641          0.235831\n",
       "longer      -1.367526          0.254736\n",
       "hairline    -1.314167          0.268698\n",
       "know        -1.197686          0.301892\n",
       "usually     -1.093983          0.334880\n",
       "style       -1.055730          0.347938\n",
       "buzz        -1.051656          0.349359\n",
       "bald        -1.022986          0.359520"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df2.sort_values(by = 'Coefficient', ascending = True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282d0752",
   "metadata": {},
   "source": [
    "**Observation:** Like the first pipeline, the words associated with feminine hairstyles and hair coloring are strong predictors of r/femalehairadvice while words to do with facial hair and hairloss are strong predictors of r/malehairadvice.\n",
    "\n",
    "There are some differences in the top 10 features as a result of the different vectorization methods. Count vectorization tokenizes features by their raw count within the corpus while Tfidf vectorization penalizes features that occur commonly throughout the corpus. For instance, the words 'long' and 'longer' appear to be among the top 10 predictors for r/malehairadvice here and not when using count vectorization. This means the words are relatively rare in the corpus and tend to come from men seeking advice about hair length. As men typically have shorter hair than women, men tend to be more sensitive to their hair length than women.\n",
    "\n",
    "Another difference between the two vectorizers are the magnitude of the coefficients for the top features. Using Tfidf vectorizer produced higher coefficient values than for count vectorizer. This is likely a result of the regularization parameter used in the logistic regression model with count vectorization which dampened the effect of overfitting. Here we observe that the word 'bang' increases the odds of predicting r/femalehairadvice by 177.7 times as compared to 5.58 times when using count vectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55a4a97",
   "metadata": {},
   "source": [
    "<a id='p3'></a>\n",
    "## Pipe 3 Naive Bayes Multinomial with Tfidf Vectorizer\n",
    "\n",
    "The naive bayes classification algorithm uses bayes' theorem to predict the probability of r/femalehairadvice given words in the document. The algorithm assumes that features are independent of one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3fcd1e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate pipeline\n",
    "pipe3 = Pipeline([\n",
    "    ('vec', TfidfVectorizer()),\n",
    "    ('model', MultinomialNB())\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e09d138c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__alpha': 0.7,\n",
       " 'model__fit_prior': False,\n",
       " 'vec__max_df': 0.15,\n",
       " 'vec__max_features': 700,\n",
       " 'vec__min_df': 3,\n",
       " 'vec__ngram_range': (1, 1),\n",
       " 'vec__stop_words': 'english'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check best parameters found during gridsearch\n",
    "best_params[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "52011776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vec',\n",
       "                 TfidfVectorizer(max_df=0.15, max_features=700, min_df=3,\n",
       "                                 stop_words='english')),\n",
       "                ('model', MultinomialNB(alpha=0.7, fit_prior=False))])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set parameters accordingly and fit to train dataset\n",
    "pipe3.set_params(model__alpha = 0.7,\n",
    "                 model__fit_prior = False,\n",
    "                 vec__max_df = 0.15,\n",
    "                 vec__max_features = 700,\n",
    "                 vec__min_df = 3,\n",
    "                 vec__ngram_range = (1, 1),\n",
    "                 vec__stop_words = 'english')\n",
    "\n",
    "pipe3.fit(train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "149bd6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store train and test accuracy scores for comparison later\n",
    "nb_train_score = pipe3.score(train_clean,y_train)\n",
    "nb_test_score = pipe3.score(test_clean,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "95150447",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Naive Bayes Multinomial with Tfidf Vectorization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Confusion Matrix for Naive Bayes Multinomial with Tfidf Vectorization')\n",
    "plot_confusion_matrix(pipe3,test_clean,y_test, cmap = 'Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c1584ae4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1597: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1597: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "#Store misclassified documents for comparison later\n",
    "misclassified_as_female3, misclassified_as_male3 = misclassifier(X = X_test,\n",
    "                                                               y_true = y_test,\n",
    "                                                               pipeline = pipe3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93a465a",
   "metadata": {},
   "source": [
    "### Feature Log probabilities\n",
    "The log probabilities of the each feature  returns the probability of the feature given a class. Since there are 2 classes, there are 2 log probabilities. It can be interpreted by exponentiating the values, then comparing the magnitudes of the probabilities. The class with the greater magnitude means that the feature predicts that particular class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c2340e2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.49416317, -7.8974569 , -7.25596188, ..., -6.79136085,\n",
       "        -6.91707783, -6.87629553],\n",
       "       [-6.84818102, -6.44319393, -7.28930992, ..., -8.11273888,\n",
       "        -7.33842092, -6.93292013]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get feature log probabilities\n",
    "nb_log_probs = pipe3['model'].feature_log_prob_\n",
    "nb_log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1dc3a672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get feature names\n",
    "features3 = pipe3['vec'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e40d7d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>Prob_feature|male</th>\n",
       "      <th>Prob_feature|female</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>grow</td>\n",
       "      <td>0.018453</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>0.011738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>beard</td>\n",
       "      <td>0.009308</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.009008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>long</td>\n",
       "      <td>0.014929</td>\n",
       "      <td>0.006924</td>\n",
       "      <td>0.008006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>barber</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.007033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>guy</td>\n",
       "      <td>0.010686</td>\n",
       "      <td>0.004151</td>\n",
       "      <td>0.006534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>buzz</td>\n",
       "      <td>0.008892</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.006467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>product</td>\n",
       "      <td>0.007643</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.005428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>know</td>\n",
       "      <td>0.009264</td>\n",
       "      <td>0.004085</td>\n",
       "      <td>0.005179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>use</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>0.002582</td>\n",
       "      <td>0.004973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>hairline</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.004436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        words  Prob_feature|male  Prob_feature|female  Difference\n",
       "244      grow           0.018453             0.006715    0.011738\n",
       "46      beard           0.009308             0.000300    0.009008\n",
       "344      long           0.014929             0.006924    0.008006\n",
       "40     barber           0.007333             0.000300    0.007033\n",
       "247       guy           0.010686             0.004151    0.006534\n",
       "78       buzz           0.008892             0.002425    0.006467\n",
       "465   product           0.007643             0.002214    0.005428\n",
       "319      know           0.009264             0.004085    0.005179\n",
       "650       use           0.007556             0.002582    0.004973\n",
       "252  hairline           0.005036             0.000600    0.004436"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combine feature names with their associated log_probs and include additional column to describe the difference betwneen\n",
    "nb_features = pd.DataFrame({'words': features3,\n",
    "                            'Prob_feature|male': np.exp(nb_log_probs[0]),\n",
    "                            'Prob_feature|female': np.exp(nb_log_probs[1])})\n",
    "nb_features['Difference'] = nb_features.loc[:,'Prob_feature|male']-nb_features.loc[:,'Prob_feature|female']\n",
    "\n",
    "#top 10 features which predict malehairadvice\n",
    "nb_features.sort_values(by = 'Difference', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "00e0a9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>Prob_feature|male</th>\n",
       "      <th>Prob_feature|female</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>bang</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.021055</td>\n",
       "      <td>-0.020467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>color</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.013183</td>\n",
       "      <td>-0.012832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>love</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.010230</td>\n",
       "      <td>-0.008166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>update</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>0.010826</td>\n",
       "      <td>-0.007624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>pixie</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.007053</td>\n",
       "      <td>-0.006703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>chop</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>-0.005139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>bob</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>-0.005112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>blonde</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.006164</td>\n",
       "      <td>-0.005058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>colour</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.004866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>curtain</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.005715</td>\n",
       "      <td>-0.004742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       words  Prob_feature|male  Prob_feature|female  Difference\n",
       "39      bang           0.000588             0.021055   -0.020467\n",
       "100    color           0.000351             0.013183   -0.012832\n",
       "351     love           0.002065             0.010230   -0.008166\n",
       "647   update           0.003201             0.010826   -0.007624\n",
       "438    pixie           0.000351             0.007053   -0.006703\n",
       "91      chop           0.002224             0.007363   -0.005139\n",
       "61       bob           0.000351             0.005462   -0.005112\n",
       "58    blonde           0.001106             0.006164   -0.005058\n",
       "101   colour           0.000407             0.005274   -0.004866\n",
       "134  curtain           0.000974             0.005715   -0.004742"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 10 features which predict femalehairadvice\n",
    "nb_features.sort_values(by = 'Difference', ascending = True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea605c3",
   "metadata": {},
   "source": [
    "**Observation:** Although the feature log probabilities is difficult to directly interpret, we see a similar pattern in the top features as compared to the logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42c0242",
   "metadata": {},
   "source": [
    "<a id='p4'></a>\n",
    "# Pipe 4 - Random Forest Classifier with Tfidf Vectorizer\n",
    "\n",
    "The Random Forest Classifier is an ensemble method that uses bootsrap aggregating to repeatedly sample the training set with replacement and constructs multiple decision trees as a result. Additionally, a random subset of features is selected for each split within the decision tree algorithm to reduce the correlation between decision trees. Correlation between trees occurs when there are few features that are strong predictors of the target class as these features will be used in many of the bagged decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9eb9bf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate Pipeline\n",
    "pipe4 = Pipeline([\n",
    "    ('vec', TfidfVectorizer()),\n",
    "    ('model', RandomForestClassifier(random_state = 25))\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c4496205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__criterion': 'gini',\n",
       " 'model__max_depth': 20,\n",
       " 'model__n_estimators': 200,\n",
       " 'vec__max_df': 0.15,\n",
       " 'vec__max_features': 2300,\n",
       " 'vec__min_df': 1,\n",
       " 'vec__ngram_range': (1, 1),\n",
       " 'vec__stop_words': 'english'}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check best parameters found during gridsearch\n",
    "best_params[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5bdfe937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vec',\n",
       "                 TfidfVectorizer(max_df=0.15, max_features=2300,\n",
       "                                 stop_words='english')),\n",
       "                ('model',\n",
       "                 RandomForestClassifier(max_depth=20, n_estimators=200,\n",
       "                                        random_state=25))])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set parameters accordingly and fit to training set\n",
    "pipe4.set_params(model__criterion = 'gini',\n",
    "                 model__max_depth = 20,\n",
    "                 model__n_estimators = 200,\n",
    "                 vec__max_df = 0.15,\n",
    "                 vec__max_features = 2300,\n",
    "                 vec__min_df = 1,\n",
    "                 vec__ngram_range = (1, 1),\n",
    "                 vec__stop_words = 'english')\n",
    "\n",
    "pipe4.fit(train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4662c4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store train and test accuracy scores for comparison later\n",
    "rf_train_score = pipe4.score(train_clean,y_train)\n",
    "rf_test_score = pipe4.score(test_clean,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a92fc545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Random Forest Classifier with Tfidf Vectorization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Confusion Matrix for Random Forest Classifier with Tfidf Vectorization')\n",
    "plot_confusion_matrix(pipe4,test_clean,y_test, cmap = 'Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "584dd49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1597: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1597: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "#Store misclassified documents for comparison later\n",
    "misclassified_as_female4, misclassified_as_male4 = misclassifier(X = X_test,\n",
    "                                                               y_true = y_test,\n",
    "                                                               pipeline = pipe4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf55557",
   "metadata": {},
   "source": [
    "### Feature importance\n",
    "\n",
    "In the Random Forest Classifier algorithm, feature importance (or gini importance) is the feature's average impurity decrease calculated from all decision trees in the forest. When the decision tree is figuring out which split to make at a given node, it picks the split that maximizes the drop in gini impurity from the parent node to the child node. Therefore a higher feature importance shows how strong of a predictor that feature is of either class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9e24b12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_importance = pipe4['model'].feature_importances_\n",
    "features4 = pipe4['vec'].get_feature_names()\n",
    "rf_features = pd.DataFrame({'Features' : features4,\n",
    "                           'Importance' : rf_importance})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5ec476bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>bang</td>\n",
       "      <td>0.093567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>color</td>\n",
       "      <td>0.074074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>love</td>\n",
       "      <td>0.030315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>pixie</td>\n",
       "      <td>0.023250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>beard</td>\n",
       "      <td>0.022983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>bob</td>\n",
       "      <td>0.021285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>barber</td>\n",
       "      <td>0.021241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>red</td>\n",
       "      <td>0.017127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>update</td>\n",
       "      <td>0.016147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>colour</td>\n",
       "      <td>0.015892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features  Importance\n",
       "170      bang    0.093567\n",
       "403     color    0.074074\n",
       "1108     love    0.030315\n",
       "1414    pixie    0.023250\n",
       "194     beard    0.022983\n",
       "249       bob    0.021285\n",
       "173    barber    0.021241\n",
       "1574      red    0.017127\n",
       "2109   update    0.016147\n",
       "404    colour    0.015892"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_features[rf_features['Importance']!=0].sort_values(by = 'Importance', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd04d8fa",
   "metadata": {},
   "source": [
    "The above table shows lists the features in descending order of importance.\n",
    "**Observation:** The strongest 6 predictive features are associated with r/femalehairadvice. In the context of Tfidf vectorization, this suggests that there are more rare words which are strongly associated with female hair as compared to male hair."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3ee203",
   "metadata": {},
   "source": [
    "<a id='p5'></a>\n",
    "# Pipe 5 - Support Vector Classifier with Tfidf Vectorizer\n",
    "\n",
    "The Support Vector Classifier (SVC) attempts to separate features by their class using a hyperplane(more than 3 features). The kernel trick used in this case was the radial basis kernel (rbf), which indicates that our features, when transformed into higher dimensions, are best separable with a radial or spherical hyperplane. The regularization hyperparameter C of the error term controls the trade-off between smooth decision boundaries and classifying the training points correctly. In this case, C was found to be optimized at 0.4 which indicates a greater priority for smooth decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fd979c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate Pipeline\n",
    "pipe5 = Pipeline([\n",
    "    ('vec', TfidfVectorizer()),\n",
    "    ('model', SVC())\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "77445aa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__C': 0.4,\n",
       " 'model__degree': 1,\n",
       " 'model__gamma': 'scale',\n",
       " 'model__kernel': 'rbf',\n",
       " 'vec__max_df': 0.1,\n",
       " 'vec__max_features': 2200,\n",
       " 'vec__min_df': 1,\n",
       " 'vec__ngram_range': (1, 1),\n",
       " 'vec__stop_words': 'english'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check best parameters found during gridsearch\n",
    "best_params[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d934e075",
   "metadata": {},
   "source": [
    "**Observation:** Note that the model regularization parameter was set as 0.4, which indicates some level of regularization to reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4562182c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vec',\n",
       "                 TfidfVectorizer(max_df=0.1, max_features=2200,\n",
       "                                 stop_words='english')),\n",
       "                ('model', SVC(C=0.4, probability=True))])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set parameters accordingly and fit to training set\n",
    "pipe5.set_params(model__C = 0.4,\n",
    "                 model__gamma = 'scale',\n",
    "                 model__kernel = 'rbf',\n",
    "                 model__probability = True,\n",
    "                 vec__max_df = 0.1,\n",
    "                 vec__max_features = 2200,\n",
    "                 vec__min_df = 1,\n",
    "                 vec__ngram_range = (1, 1),\n",
    "                 vec__stop_words = 'english')\n",
    "\n",
    "pipe5.fit(train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "23fb1f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store train and test accuracy scores for comparison later\n",
    "svc_train_score = pipe5.score(train_clean,y_train)\n",
    "svc_test_score = pipe5.score(test_clean,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a7f85103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Support Vector Classifier with Tfidf Vectorization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Confusion Matrix for Support Vector Classifier with Tfidf Vectorization')\n",
    "plot_confusion_matrix(pipe5,test_clean,y_test, cmap = 'Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "45d84ce5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1597: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1597: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "C:\\Users\\chris\\anaconda3\\envs\\dsi\\lib\\site-packages\\pandas\\core\\indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "misclassified_as_female5, misclassified_as_male5 = misclassifier(X = X_test,\n",
    "                                                               y_true = y_test,\n",
    "                                                               pipeline = pipe5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586dbdd4",
   "metadata": {},
   "source": [
    "### Black Box model\n",
    "\n",
    "The Support Vector Classifier, when using non-linear kernels, is essentially a black box model and making its parameters difficult to interpret. In this case, the RBF kernel was used which is better at estimating features in higher dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0617e6d4",
   "metadata": {},
   "source": [
    "<a id='compare'></a>\n",
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8921398",
   "metadata": {},
   "source": [
    "<a id='vec'></a>\n",
    "## Count Vectorizer vs Tfidf Vectorizer\n",
    "\n",
    "Count Vectorizer and Tfidf Vectorizer are transformers which tokenize the documents into numbers representing each feature. For the Count Vectorizer, features are transformed into the number of occurences for each feature per document. For the Tfidf Vectorizer, words that are common throughout the corpus are penalized. Therefore the features with greater emphasis are those which are rare throughout the corpus but common in a certain documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6608f4a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__C': 0.1,\n",
       " 'model__max_iter': 500,\n",
       " 'vec__max_df': 0.2,\n",
       " 'vec__max_features': 500,\n",
       " 'vec__min_df': 4,\n",
       " 'vec__ngram_range': (1, 1),\n",
       " 'vec__stop_words': 'english'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking best parameters for pipeline 1\n",
    "best_params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "374b8817",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__C': 1,\n",
       " 'model__max_iter': 1000,\n",
       " 'vec__max_df': 0.1,\n",
       " 'vec__max_features': 1200,\n",
       " 'vec__min_df': 1,\n",
       " 'vec__ngram_range': (1, 1),\n",
       " 'vec__stop_words': 'english'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking best parameters for pipeline 2\n",
    "best_params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a237fae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate vectorizers using the best parameters used in the logistic regression models\n",
    "cvec = CountVectorizer(max_df = 0.2,\n",
    "                       max_features = 500,\n",
    "                       min_df = 4,\n",
    "                       ngram_range = (1, 1),\n",
    "                       stop_words = 'english')\n",
    "tvec = TfidfVectorizer(max_df = 0.1,\n",
    "                      max_features = 1200,\n",
    "                      min_df = 1,\n",
    "                      ngram_range = (1,1),\n",
    "                      stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c5420695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the sparse matrix for the transformed features, add the values for each row and return an array.\n",
    "response_c = cvec.fit_transform(train_clean,y_train).toarray().sum(axis = 0)\n",
    "response_t = tvec.fit_transform(train_clean,y_train).toarray().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0f16391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the tokens after vectorization\n",
    "cvec_vocab = cvec.get_feature_names()\n",
    "tvec_vocab = tvec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f6f15e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put together the features and their respective sums after transformation\n",
    "cvec_features = pd.DataFrame(index = cvec_vocab, data = response_c).rename(columns = {0:'Count'})\n",
    "tvec_features = pd.DataFrame(index = tvec_vocab, data = response_t).rename(columns = {0:'Importance'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7b114815",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cut</th>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>look</th>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grow</th>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long</th>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bang</th>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short</th>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help</th>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Count\n",
       "cut      345\n",
       "look     312\n",
       "think    239\n",
       "grow     199\n",
       "long     178\n",
       "bang     176\n",
       "short    154\n",
       "year     130\n",
       "help     118\n",
       "good     117"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec_features.sort_values(by = 'Count', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "44b6e708",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Increase in odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cut</th>\n",
       "      <td>0.039365</td>\n",
       "      <td>1.040150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>look</th>\n",
       "      <td>-0.186585</td>\n",
       "      <td>0.829788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>0.142702</td>\n",
       "      <td>1.153386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grow</th>\n",
       "      <td>-0.391789</td>\n",
       "      <td>0.675847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long</th>\n",
       "      <td>-0.281080</td>\n",
       "      <td>0.754968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bang</th>\n",
       "      <td>1.719675</td>\n",
       "      <td>5.582716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short</th>\n",
       "      <td>0.183093</td>\n",
       "      <td>1.200926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>-0.170850</td>\n",
       "      <td>0.842948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help</th>\n",
       "      <td>0.075890</td>\n",
       "      <td>1.078843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>-0.150234</td>\n",
       "      <td>0.860507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Coefficient  Increase in odds\n",
       "cut       0.039365          1.040150\n",
       "look     -0.186585          0.829788\n",
       "think     0.142702          1.153386\n",
       "grow     -0.391789          0.675847\n",
       "long     -0.281080          0.754968\n",
       "bang      1.719675          5.582716\n",
       "short     0.183093          1.200926\n",
       "year     -0.170850          0.842948\n",
       "help      0.075890          1.078843\n",
       "good     -0.150234          0.860507"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df1.loc[['cut','look','think','grow','long','bang','short','year','help','good']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce69ea3",
   "metadata": {},
   "source": [
    "**Observation:** For count vectorizer, we see that the count of each token is not necessarily reflective of their predictive value. For instance, of the top 10 words by count, only a handful show a significant increase (>25%) in odds for predicting r/femalehairadvice. Namely 'grow' and 'bang'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "490c71a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bang</th>\n",
       "      <td>46.390068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short</th>\n",
       "      <td>44.432571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suit</th>\n",
       "      <td>34.324548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help</th>\n",
       "      <td>32.805759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>32.274122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thanks</th>\n",
       "      <td>31.889791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>31.746841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guy</th>\n",
       "      <td>30.197300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suggestion</th>\n",
       "      <td>29.773470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>update</th>\n",
       "      <td>29.121014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Importance\n",
       "bang         46.390068\n",
       "short        44.432571\n",
       "suit         34.324548\n",
       "help         32.805759\n",
       "good         32.274122\n",
       "thanks       31.889791\n",
       "year         31.746841\n",
       "guy          30.197300\n",
       "suggestion   29.773470\n",
       "update       29.121014"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvec_features.sort_values(by = 'Importance', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0ef7d1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Increase in odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bang</th>\n",
       "      <td>5.186504</td>\n",
       "      <td>178.842242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short</th>\n",
       "      <td>-0.155377</td>\n",
       "      <td>0.856092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suit</th>\n",
       "      <td>0.386867</td>\n",
       "      <td>1.472360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help</th>\n",
       "      <td>-0.152946</td>\n",
       "      <td>0.858176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>-0.515964</td>\n",
       "      <td>0.596925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thanks</th>\n",
       "      <td>0.596196</td>\n",
       "      <td>1.815201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>-0.567716</td>\n",
       "      <td>0.566819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guy</th>\n",
       "      <td>-1.015773</td>\n",
       "      <td>0.362122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suggestion</th>\n",
       "      <td>-0.284518</td>\n",
       "      <td>0.752377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>update</th>\n",
       "      <td>1.624534</td>\n",
       "      <td>5.076052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Coefficient  Increase in odds\n",
       "bang           5.186504        178.842242\n",
       "short         -0.155377          0.856092\n",
       "suit           0.386867          1.472360\n",
       "help          -0.152946          0.858176\n",
       "good          -0.515964          0.596925\n",
       "thanks         0.596196          1.815201\n",
       "year          -0.567716          0.566819\n",
       "guy           -1.015773          0.362122\n",
       "suggestion    -0.284518          0.752377\n",
       "update         1.624534          5.076052"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df2.loc[['bang','short','suit','help','good','thanks','year','guy','suggestion','update']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993cfd02",
   "metadata": {},
   "source": [
    "Since Tfidf penalizes words that are common throughout the corpus. The tf–idf value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word. This helps to adjust for the fact that some words appear frequently throughout the corpus. Therefore the sum of each token value is a rough measure of the relative importance of that token within the corpus.\n",
    "\n",
    "**Observation:** Several tokens from the top 10 highest counts from count vectorizer do not appear in the top 10 tokens by importance from the tfidf vectorizer. The words 'cut', 'look', 'think', 'grow' and 'long' seem to be of relative low importance in the corpus.\n",
    "\n",
    "Of the top 10 tokens by importance from tfidf vectorization, many of the features show a significant (>25%) increase in odds of predicting r/femalehairadvice. For instance, 'bang' has a 177.6 times increase in odds of predicting r/femalehairadvice, likewise, 'guy' decreases the odds to 0.366 times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17f2355",
   "metadata": {},
   "source": [
    "### Tfidf Vectorizer for Search Engine Optimization\n",
    "\n",
    "The Tfidf Vectorizer was selected over Count Vectorizer as it reduces the importance of words that may not provide predictive value but are commonly used. This is more suited for building search engine optimization algorithms as it emphasizes words that frequently used for a given classification type. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6529028",
   "metadata": {},
   "source": [
    "<a id='eval'></a>\n",
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03faba52",
   "metadata": {},
   "source": [
    "### Testing on unseen data from new posts\n",
    "\n",
    "Hair styles and trends for each gender change over time. To test the robustness of the models, I scraped 500 new posts from both subreddits to score the models and evaluate how they handle a larger sample of unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "62e677da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating model performance on unseen data\n",
    "unseen_score1 = pipe1.score(unseen_clean, y_unseen)\n",
    "unseen_score2 = pipe2.score(unseen_clean, y_unseen)\n",
    "unseen_score3 = pipe3.score(unseen_clean, y_unseen)\n",
    "unseen_score4 = pipe4.score(unseen_clean, y_unseen)\n",
    "unseen_score5 = pipe5.score(unseen_clean, y_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d586741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rounding scores to 3sf and creating dictionary to convert to dataframe\n",
    "all_model_scores = {'Log Reg Count Vectorizer' : [round(log_reg_count_train_score, 3),\n",
    "                                                  round(log_reg_count_test_score,3),\n",
    "                                                  round(unseen_score1,3),\n",
    "                                                  round(log_reg_count_train_score-log_reg_count_test_score,3),\n",
    "                                                  round(log_reg_count_train_score-unseen_score1,3),\n",
    "                                                  round((log_reg_count_train_score-log_reg_count_test_score) + (log_reg_count_train_score-unseen_score1),3)\n",
    "                                                  ],\n",
    "                   'Log Reg Tfidf Vectorizer' : [round(log_reg_tfidf_train_score,3),\n",
    "                                                 round(log_reg_tfidf_test_score,3),\n",
    "                                                 round(unseen_score2,3),\n",
    "                                                 round(log_reg_tfidf_train_score-log_reg_tfidf_test_score,3),\n",
    "                                                 round(log_reg_tfidf_train_score-unseen_score2,3),\n",
    "                                                 round((log_reg_tfidf_train_score-log_reg_tfidf_test_score) + (log_reg_tfidf_train_score-unseen_score2),3)\n",
    "                                                 ],\n",
    "                   'Naive Bayes Multinomial': [round(nb_train_score,3),\n",
    "                                               round(nb_test_score,3),\n",
    "                                               round(unseen_score3,3),\n",
    "                                               round(nb_train_score-nb_test_score,3),\n",
    "                                               round(nb_train_score-unseen_score3,3),\n",
    "                                               round((nb_train_score-nb_test_score) + (nb_train_score-unseen_score3),3)\n",
    "                                               ],\n",
    "                   'Random Forest Classifier' : [round(rf_train_score,3),\n",
    "                                                 round(rf_test_score,3),\n",
    "                                                 round(unseen_score4,3),\n",
    "                                                 round(rf_train_score-rf_test_score,3),\n",
    "                                                 round(rf_train_score-unseen_score4,3),\n",
    "                                                 round((rf_train_score-rf_test_score) +(rf_train_score-unseen_score4),3)\n",
    "                                                 ],\n",
    "                   'Support Vector Classifier' : [round(svc_train_score,3),\n",
    "                                                  round(svc_test_score,3),\n",
    "                                                  round(unseen_score5,3),\n",
    "                                                  round(svc_train_score-svc_test_score,3),\n",
    "                                                  round(svc_train_score-unseen_score5,3),\n",
    "                                                  round((svc_train_score-svc_test_score) + (svc_train_score-unseen_score5),3)\n",
    "                                                  ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "823b49cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Log Reg Count Vectorizer': [0.85, 0.811, 0.792, 0.039, 0.059, 0.098],\n",
       " 'Log Reg Tfidf Vectorizer': [0.901, 0.827, 0.798, 0.074, 0.104, 0.178],\n",
       " 'Naive Bayes Multinomial': [0.891, 0.823, 0.814, 0.068, 0.078, 0.146],\n",
       " 'Random Forest Classifier': [0.898, 0.807, 0.782, 0.091, 0.116, 0.207],\n",
       " 'Support Vector Classifier': [0.935, 0.811, 0.796, 0.124, 0.139, 0.263]}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fb4e3216",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table of Accuracy scores for the different models\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log Reg Count Vectorizer</th>\n",
       "      <th>Log Reg Tfidf Vectorizer</th>\n",
       "      <th>Naive Bayes Multinomial</th>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <th>Support Vector Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Score</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Score</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unseen Score</th>\n",
       "      <td>0.792</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train/Test Accuracy Drop</th>\n",
       "      <td>0.039</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test/Unseen Accuracy Drop</th>\n",
       "      <td>0.059</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Accuracy Drop</th>\n",
       "      <td>0.098</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Log Reg Count Vectorizer  Log Reg Tfidf Vectorizer  \\\n",
       "Train Score                                   0.850                     0.901   \n",
       "Test Score                                    0.811                     0.827   \n",
       "Unseen Score                                  0.792                     0.798   \n",
       "Train/Test Accuracy Drop                      0.039                     0.074   \n",
       "Test/Unseen Accuracy Drop                     0.059                     0.104   \n",
       "Total Accuracy Drop                           0.098                     0.178   \n",
       "\n",
       "                           Naive Bayes Multinomial  Random Forest Classifier  \\\n",
       "Train Score                                  0.891                     0.898   \n",
       "Test Score                                   0.823                     0.807   \n",
       "Unseen Score                                 0.814                     0.782   \n",
       "Train/Test Accuracy Drop                     0.068                     0.091   \n",
       "Test/Unseen Accuracy Drop                    0.078                     0.116   \n",
       "Total Accuracy Drop                          0.146                     0.207   \n",
       "\n",
       "                           Support Vector Classifier  \n",
       "Train Score                                    0.935  \n",
       "Test Score                                     0.811  \n",
       "Unseen Score                                   0.796  \n",
       "Train/Test Accuracy Drop                       0.124  \n",
       "Test/Unseen Accuracy Drop                      0.139  \n",
       "Total Accuracy Drop                            0.263  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_comparison = pd.DataFrame(data = all_model_scores, index = ['Train Score', 'Test Score','Unseen Score','Train/Test Accuracy Drop','Test/Unseen Accuracy Drop', 'Total Accuracy Drop'])\n",
    "print('Table of Accuracy scores for the different models')\n",
    "score_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208c116c",
   "metadata": {},
   "source": [
    "**Observation:** All 5 models had a significant improvement in accuracy scores on the training dataset as compared to the baseline score (50.2%). The top 3 models which showed highest test accuracies are:\n",
    "\n",
    "1) Naive Bayes Multinomial\n",
    "2) Logistic Regression\n",
    "3) Support Vector Classifier\n",
    "\n",
    "We can analyse the `Train/Test Accuracy Drop` to gauge the extent of overfitting for each model. Having a higher accuracy drop means greater overfitting which is something we wish to avoid to ensure that our model can generalize better over new data. This can be an important issue with regards to hair styles and trends as they change over time. To further test the robustness of our models, a second test was performed using a dataset scraped from new posts from each subreddit. The `Test/Unseen Accuracy Drop` is then computed to measure each model's robustness when accounting for the latest hair trends.\n",
    "\n",
    "The top 3 models which show the most robust performance (ie. lowest total accuracy drop) are:\n",
    "\n",
    "1) Naive Bayes Multinomial\n",
    "2) Logistic Regression\n",
    "3) Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5130e4",
   "metadata": {},
   "source": [
    "Since our secondary stakeholders are made up of mostly female, we want the model which is optimized for the **True Positive Rate** which means we want to maximize the **sensitivity (or recall)** of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2011ba39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report for Logreg with Cvec \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83       251\n",
      "           1       0.90      0.69      0.78       246\n",
      "\n",
      "    accuracy                           0.81       497\n",
      "   macro avg       0.83      0.81      0.81       497\n",
      "weighted avg       0.83      0.81      0.81       497\n",
      "\n",
      "classification report for Logreg with Tvec \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       251\n",
      "           1       0.87      0.77      0.81       246\n",
      "\n",
      "    accuracy                           0.83       497\n",
      "   macro avg       0.83      0.83      0.83       497\n",
      "weighted avg       0.83      0.83      0.83       497\n",
      "\n",
      "classification report for Naive Bayes \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       251\n",
      "           1       0.84      0.80      0.82       246\n",
      "\n",
      "    accuracy                           0.82       497\n",
      "   macro avg       0.82      0.82      0.82       497\n",
      "weighted avg       0.82      0.82      0.82       497\n",
      "\n",
      "classification report for Random Forest \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83       251\n",
      "           1       0.89      0.69      0.78       246\n",
      "\n",
      "    accuracy                           0.81       497\n",
      "   macro avg       0.82      0.81      0.80       497\n",
      "weighted avg       0.82      0.81      0.80       497\n",
      "\n",
      "classification report for Support Vector \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.91      0.83       251\n",
      "           1       0.89      0.71      0.79       246\n",
      "\n",
      "    accuracy                           0.81       497\n",
      "   macro avg       0.82      0.81      0.81       497\n",
      "weighted avg       0.82      0.81      0.81       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('classification report for Logreg with Cvec \\n' + classification_report(y_test,pipe1.predict(test_clean)))\n",
    "print('classification report for Logreg with Tvec \\n' + classification_report(y_test,pipe2.predict(test_clean)))\n",
    "print('classification report for Naive Bayes \\n' + classification_report(y_test,pipe3.predict(test_clean)))\n",
    "print('classification report for Random Forest \\n' + classification_report(y_test,pipe4.predict(test_clean)))\n",
    "print('classification report for Support Vector \\n' + classification_report(y_test,pipe5.predict(test_clean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c54e29",
   "metadata": {},
   "source": [
    "From the recall values for each model with respect to predicting class = 1, we observe that models with the best sensitivity are:\n",
    "1) Naive Bayes Multinomial (80%)\n",
    "2) Logistic Regression (76%)\n",
    "\n",
    "**Observation:** The recall with respect to class = 0 is consistently higher than the recall with respect to class = 1. This is consistent with the fact that there are more false negatives than false positives from our predictions. This means many of the misclassifications were actually from r/femalehairadvice but were falsely predicted to be from r/malehairadvice. Now that we have narrowed the models down to 2, we can explore this further by looking at the documents which were misclassified by both of these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "88452e58",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['get stir crazy try grow out dye come out far dark cut off start bang',\n",
       " 'get soon know direction go maybe look change please advise',\n",
       " 'back blonde undercut p please ignore fact still wet in picture excite wait dry',\n",
       " 'castor oil make fine straight wavyhi everyone lurk love information useless recently use castor oil on fine straight give really nice wave first time think would share experience in case help anyone fine generally straight little wavy in certain circumstance never able control wave though tried curly girl method experiment sort product tend dry frizzy product control frizz way heavy make greasy even leave in conditioner not really option recently use castor oil on get nice wave first time picture buy b well organic cold press castor oil put on wet shampoo conditioner let sit min shampooed condition normal expectation sleep on wet wake up nice wave on day two look greasy yet call win x b x b http preview redd lpcsc f nkk jpg width format pjpg auto webp c cd b ecd eb',\n",
       " 'million view on tiktok hundred duet try do think',\n",
       " 'cut inch off',\n",
       " 'one year growth trim in',\n",
       " 'welcome',\n",
       " 'get curl stay put',\n",
       " 'routine go straight curly know decide',\n",
       " 'get bang gotta say really pleased',\n",
       " 'finally gonna rid lockdown think layer middle part bang',\n",
       " 'mom try find good thought would awesome ask guy advise something grows super fast',\n",
       " 'do give brush fluffy',\n",
       " 'help badly hairline recede do do year old please excuse post run sweaty brow',\n",
       " 'new cherry thought',\n",
       " 'cut short always long straight across bang leave top left pic',\n",
       " 'uhh cut bang know leave another please help',\n",
       " 'since look healthy idea naturally curly braid bed time',\n",
       " 'get do on sunday since middle school need change',\n",
       " 'product general recommendation make look well alive air dry real lazy ideally product continue lazy dry thick coarse bleach in mids end',\n",
       " 'hello look cut active main requirement either pull back short enough stay out face',\n",
       " 'would look good bang first in year schedule weekend try something new worried make look young suit face',\n",
       " 'survive extreme case pneumonia exactly one year ago lose much fluffies up top regrowth thankful always look fine suggestion tame babe',\n",
       " 'would ginger suit natural look',\n",
       " 'please help first time get cut hairdresser in year know ask think mousy brown big forehead maybe diamond shape face not sure do think would suit',\n",
       " 'become inspired get',\n",
       " 'covid see another human in two week today give bang reason nearly cry stepped away mirror lol please nice',\n",
       " 'do stop look matted curl use heat protectant mask x week anti frizz oil wash let air dry always',\n",
       " 'look way help deal unruly wispy hair yet find product tool calm baby down',\n",
       " 'look',\n",
       " 'do cut shoulder jaw length do grow out please help uninspired',\n",
       " 'grow past year wonder time little change recommendation thought square face btw',\n",
       " 'hello really long go down low back thick frizzy look good straighten braided curl require every wash look okay on right straight layer',\n",
       " 'do look time suggestion',\n",
       " 'could out face feel lay flat on head favor especially side usually wear up in last two pic could look good on',\n",
       " 'flat thin little change in routine look much fluffy soft best look in long time change in comment',\n",
       " 'bang keep grow out never end dilemma',\n",
       " 'know do wavy think look much good one side pull back ready major change in color',\n",
       " 'n',\n",
       " 'get recommendation get bang thank lovely amazing people subreddit',\n",
       " 'try improve look come lost do think would suit',\n",
       " 'wonder bang bang never short really needing change',\n",
       " 'help weird thing curl in on right side out on left side do need do make fall down normally on side',\n",
       " 'thin straight not much volume bit thanks blond highlight long face pretty long forehead really know do',\n",
       " 'stick short currently leave grow out bob really stick on suit face shape well',\n",
       " 'ive live died side part bit insecure forehead wonder part guy think look best maybe time change not lol',\n",
       " 'hope alright post on always felt rocked woman well men think start new year off get mullet do think could pull off attach idea in comment hehe thank',\n",
       " 'difference cut curl friendly product make frizzy straight might curl wait emerge',\n",
       " 'chop inch off help end',\n",
       " 'bore cut bang call em quarantine bang xd regret',\n",
       " 'debate cut current on left previous shorter on right do think look good long short would recommend cool try next consider mullet not sure length suit',\n",
       " 'update long lob obsess may never go long original post http r comment ir dsc tomorrow almost sure im ask lob http r comment ir dsc tomorrow almost sure im ask lob x b http preview redd qf w tcq n jpg width format pjpg auto webp c ce fedc f cf b b',\n",
       " 'since grow tired feel well suit face shape personality loss please help bonus photo typically out way',\n",
       " 'do conflict',\n",
       " 'thanks great get recommended oil cure porcupine head grow out buzz cut soft',\n",
       " 'hairloss worth see doctor',\n",
       " 'upcoming salon apt much need something face frame suggestion appreciate',\n",
       " 'do face pull off shorter on right think get on leave get large nose not define bone structure worry look weird',\n",
       " 'think new haircolor do think ombre blonde',\n",
       " 'one suit best',\n",
       " 'car recommendation read comment detailed description',\n",
       " 'rest decent thickness ive lose in back part proactive take lot vitamin also use topikk daily cover up ugly wonder anyone try talk family could care less',\n",
       " 'middle side part',\n",
       " 'cut short pic look short not currently mid chest length',\n",
       " 'anyone say yet',\n",
       " 'messy space bun',\n",
       " 'yesterday donate inch little princess trust proud also kinda hate new scared way besides half up look tip grow out wear in way hide short',\n",
       " 'get subtle sun kiss highlight first time ever love',\n",
       " 'fire literally',\n",
       " 'ok basically snapchat filter question life decision deader dead really make shave off maybe leave little bleach opinion',\n",
       " 'growth curl progress look well',\n",
       " 'tire short love go something different im think short layer type bang not sure right face though would suit another try',\n",
       " 'hello everyone could general would look good thinking maybe ombr unsure',\n",
       " 'long short feel bit insecure do guy think',\n",
       " 'first in year idea make wave easy form',\n",
       " 'update get thanks support',\n",
       " 'grow year scar mess up bad cut think bang really need',\n",
       " 'do think feeling inspire today',\n",
       " 'recently out trans idea do look straighten tip idea anything related',\n",
       " 'buzz bleach in love never do anything wild shoutout sub buzzcut bleach tip',\n",
       " 'do maintain take care treat randomly curly in back underneath straight everywhere else']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get false negatives from pipe 2 and 3\n",
    "list(set(misclassified_as_male2['Cleaned Documents']) & \n",
    "     set(misclassified_as_male3['Cleaned Documents']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5d754c49",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello baby face advice',\n",
       " 'get chop off not long ago pretty happy result',\n",
       " 'update hopefully cool post finally get big glass think make difference thanks everyone help',\n",
       " 'long beach wave fun last',\n",
       " 'would suit see second photo',\n",
       " 'do fix thing',\n",
       " 'thanks inspiration guy',\n",
       " 'long awhile ready chop off do one pic down one pic back face shape visible thinner face many others feel fivehead lmk post profile shot',\n",
       " 'need help current',\n",
       " 'confidence wear out personally love do guy think',\n",
       " 'would ask',\n",
       " 'post little ago update',\n",
       " 'slick back year decide on drastic change needless say fricking love']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get false positives from pipe 2 and 3\n",
    "list(set(misclassified_as_female2['Cleaned Documents']) & \n",
    "     set(misclassified_as_female3['Cleaned Documents']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641e3051",
   "metadata": {},
   "source": [
    "A major limitation in our classification problem is the length of the documents. Several of the misclassifications are short documents containing 5 words or less. This can easily lead to misclassifications as there is simply not enough words in the document to make an accurate prediction.\n",
    "\n",
    "Another limitation is the feature coefficients/importance. From the analyses of the individual pipelines, we observe that features that are associated with r/femalehairadvice tend to be words that describe a variety of hairstyles (pixie, bob, bangs) and hair colors (color, colour, blonde, red,black, balayage, brown). On the other hand, for r/malehairadvice, the words that describe hairstyles tend to be limited (beard, buzz, recede, hairline, bald). This is reflective of the difference in types of specialized hair styles and treatments catered to women. As a result, the vocabulary bank which describes female hair is much more varied than male hair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "35e6b4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Increase in odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bang</th>\n",
       "      <td>5.186504</td>\n",
       "      <td>178.842242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color</th>\n",
       "      <td>3.972480</td>\n",
       "      <td>53.116093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>2.640218</td>\n",
       "      <td>14.016261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pixie</th>\n",
       "      <td>2.623608</td>\n",
       "      <td>13.785371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colour</th>\n",
       "      <td>2.281447</td>\n",
       "      <td>9.790838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blonde</th>\n",
       "      <td>2.086993</td>\n",
       "      <td>8.060637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bob</th>\n",
       "      <td>2.063674</td>\n",
       "      <td>7.874848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chop</th>\n",
       "      <td>1.697612</td>\n",
       "      <td>5.460894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dye</th>\n",
       "      <td>1.688176</td>\n",
       "      <td>5.409604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red</th>\n",
       "      <td>1.664538</td>\n",
       "      <td>5.283231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>update</th>\n",
       "      <td>1.624534</td>\n",
       "      <td>5.076052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>1.588735</td>\n",
       "      <td>4.897550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ago</th>\n",
       "      <td>1.490347</td>\n",
       "      <td>4.438633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balayage</th>\n",
       "      <td>1.469430</td>\n",
       "      <td>4.346755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brown</th>\n",
       "      <td>1.464773</td>\n",
       "      <td>4.326562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Coefficient  Increase in odds\n",
       "bang         5.186504        178.842242\n",
       "color        3.972480         53.116093\n",
       "love         2.640218         14.016261\n",
       "pixie        2.623608         13.785371\n",
       "colour       2.281447          9.790838\n",
       "blonde       2.086993          8.060637\n",
       "bob          2.063674          7.874848\n",
       "chop         1.697612          5.460894\n",
       "dye          1.688176          5.409604\n",
       "red          1.664538          5.283231\n",
       "update       1.624534          5.076052\n",
       "black        1.588735          4.897550\n",
       "ago          1.490347          4.438633\n",
       "balayage     1.469430          4.346755\n",
       "brown        1.464773          4.326562"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top features which predit r/femalehairadvice for logistic regression model\n",
    "coef_df2.sort_values(by = 'Coefficient', ascending = False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7ca113a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Increase in odds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>barber</th>\n",
       "      <td>-2.467369</td>\n",
       "      <td>0.084808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beard</th>\n",
       "      <td>-2.378340</td>\n",
       "      <td>0.092704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recede</th>\n",
       "      <td>-1.444641</td>\n",
       "      <td>0.235831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longer</th>\n",
       "      <td>-1.367526</td>\n",
       "      <td>0.254736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hairline</th>\n",
       "      <td>-1.314167</td>\n",
       "      <td>0.268698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>-1.197686</td>\n",
       "      <td>0.301892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usually</th>\n",
       "      <td>-1.093983</td>\n",
       "      <td>0.334880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>style</th>\n",
       "      <td>-1.055730</td>\n",
       "      <td>0.347938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buzz</th>\n",
       "      <td>-1.051656</td>\n",
       "      <td>0.349359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bald</th>\n",
       "      <td>-1.022986</td>\n",
       "      <td>0.359520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guy</th>\n",
       "      <td>-1.015773</td>\n",
       "      <td>0.362122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product</th>\n",
       "      <td>-0.994299</td>\n",
       "      <td>0.369983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quarantine</th>\n",
       "      <td>-0.984694</td>\n",
       "      <td>0.373554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trim</th>\n",
       "      <td>-0.931201</td>\n",
       "      <td>0.394080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fade</th>\n",
       "      <td>-0.930740</td>\n",
       "      <td>0.394262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Coefficient  Increase in odds\n",
       "barber        -2.467369          0.084808\n",
       "beard         -2.378340          0.092704\n",
       "recede        -1.444641          0.235831\n",
       "longer        -1.367526          0.254736\n",
       "hairline      -1.314167          0.268698\n",
       "know          -1.197686          0.301892\n",
       "usually       -1.093983          0.334880\n",
       "style         -1.055730          0.347938\n",
       "buzz          -1.051656          0.349359\n",
       "bald          -1.022986          0.359520\n",
       "guy           -1.015773          0.362122\n",
       "product       -0.994299          0.369983\n",
       "quarantine    -0.984694          0.373554\n",
       "trim          -0.931201          0.394080\n",
       "fade          -0.930740          0.394262"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top features which predict r/malehairadvice for logistic regression model\n",
    "coef_df2.sort_values(by = 'Coefficient', ascending = True).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8e3a01ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>Prob_feature|male</th>\n",
       "      <th>Prob_feature|female</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>bang</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.021055</td>\n",
       "      <td>-0.020467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>color</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.013183</td>\n",
       "      <td>-0.012832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>love</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.010230</td>\n",
       "      <td>-0.008166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>update</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>0.010826</td>\n",
       "      <td>-0.007624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>pixie</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.007053</td>\n",
       "      <td>-0.006703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>chop</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>-0.005139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>bob</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>-0.005112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>blonde</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.006164</td>\n",
       "      <td>-0.005058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>colour</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.004866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>curtain</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.005715</td>\n",
       "      <td>-0.004742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>thank</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>0.007303</td>\n",
       "      <td>-0.004650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>dye</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>-0.004550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>red</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.005014</td>\n",
       "      <td>-0.004484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>balayage</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>-0.003572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>brown</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.003848</td>\n",
       "      <td>-0.003498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        words  Prob_feature|male  Prob_feature|female  Difference\n",
       "39       bang           0.000588             0.021055   -0.020467\n",
       "100     color           0.000351             0.013183   -0.012832\n",
       "351      love           0.002065             0.010230   -0.008166\n",
       "647    update           0.003201             0.010826   -0.007624\n",
       "438     pixie           0.000351             0.007053   -0.006703\n",
       "91       chop           0.002224             0.007363   -0.005139\n",
       "61        bob           0.000351             0.005462   -0.005112\n",
       "58     blonde           0.001106             0.006164   -0.005058\n",
       "101    colour           0.000407             0.005274   -0.004866\n",
       "134   curtain           0.000974             0.005715   -0.004742\n",
       "599     thank           0.002653             0.007303   -0.004650\n",
       "162       dye           0.000755             0.005306   -0.004550\n",
       "490       red           0.000530             0.005014   -0.004484\n",
       "36   balayage           0.000351             0.003922   -0.003572\n",
       "72      brown           0.000351             0.003848   -0.003498"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top features which predict r/femalehairadvice for naive bayes model\n",
    "nb_features.sort_values(by = 'Difference', ascending = True).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eb782ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>Prob_feature|male</th>\n",
       "      <th>Prob_feature|female</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>grow</td>\n",
       "      <td>0.018453</td>\n",
       "      <td>0.006715</td>\n",
       "      <td>0.011738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>beard</td>\n",
       "      <td>0.009308</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.009008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>long</td>\n",
       "      <td>0.014929</td>\n",
       "      <td>0.006924</td>\n",
       "      <td>0.008006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>barber</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.007033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>guy</td>\n",
       "      <td>0.010686</td>\n",
       "      <td>0.004151</td>\n",
       "      <td>0.006534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>buzz</td>\n",
       "      <td>0.008892</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>0.006467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>product</td>\n",
       "      <td>0.007643</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.005428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>know</td>\n",
       "      <td>0.009264</td>\n",
       "      <td>0.004085</td>\n",
       "      <td>0.005179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>use</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>0.002582</td>\n",
       "      <td>0.004973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>hairline</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.004436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>longer</td>\n",
       "      <td>0.005658</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.004375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>style</td>\n",
       "      <td>0.007336</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>0.004308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>recede</td>\n",
       "      <td>0.004552</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.004253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>good</td>\n",
       "      <td>0.010319</td>\n",
       "      <td>0.006085</td>\n",
       "      <td>0.004234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>year</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>0.006183</td>\n",
       "      <td>0.003494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        words  Prob_feature|male  Prob_feature|female  Difference\n",
       "244      grow           0.018453             0.006715    0.011738\n",
       "46      beard           0.009308             0.000300    0.009008\n",
       "344      long           0.014929             0.006924    0.008006\n",
       "40     barber           0.007333             0.000300    0.007033\n",
       "247       guy           0.010686             0.004151    0.006534\n",
       "78       buzz           0.008892             0.002425    0.006467\n",
       "465   product           0.007643             0.002214    0.005428\n",
       "319      know           0.009264             0.004085    0.005179\n",
       "650       use           0.007556             0.002582    0.004973\n",
       "252  hairline           0.005036             0.000600    0.004436\n",
       "345    longer           0.005658             0.001283    0.004375\n",
       "578     style           0.007336             0.003028    0.004308\n",
       "485    recede           0.004552             0.000300    0.004253\n",
       "235      good           0.010319             0.006085    0.004234\n",
       "693      year           0.009676             0.006183    0.003494"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top features which predict r/malehairadvice for naive bayes model\n",
    "nb_features.sort_values(by = 'Difference', ascending = False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e562f3",
   "metadata": {},
   "source": [
    "<a id='select'></a>\n",
    "## Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "df4af420",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log Reg Tfidf Vectorizer</th>\n",
       "      <th>Naive Bayes Multinomial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train Score</th>\n",
       "      <td>0.901</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Score</th>\n",
       "      <td>0.827</td>\n",
       "      <td>0.823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unseen Score</th>\n",
       "      <td>0.798</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train/Test Accuracy Drop</th>\n",
       "      <td>0.074</td>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test/Unseen Accuracy Drop</th>\n",
       "      <td>0.029</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Accuracy Drop</th>\n",
       "      <td>0.104</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Log Reg Tfidf Vectorizer  Naive Bayes Multinomial\n",
       "Train Score                                   0.901                    0.891\n",
       "Test Score                                    0.827                    0.823\n",
       "Unseen Score                                  0.798                    0.814\n",
       "Train/Test Accuracy Drop                      0.074                    0.068\n",
       "Test/Unseen Accuracy Drop                     0.029                    0.009\n",
       "Total Accuracy Drop                           0.104                    0.078"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_comparison[['Log Reg Tfidf Vectorizer','Naive Bayes Multinomial']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "45ab79dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report for Logreg with Tvec \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       251\n",
      "           1       0.87      0.77      0.81       246\n",
      "\n",
      "    accuracy                           0.83       497\n",
      "   macro avg       0.83      0.83      0.83       497\n",
      "weighted avg       0.83      0.83      0.83       497\n",
      "\n",
      "classification report for Naive Bayes \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       251\n",
      "           1       0.84      0.80      0.82       246\n",
      "\n",
      "    accuracy                           0.82       497\n",
      "   macro avg       0.82      0.82      0.82       497\n",
      "weighted avg       0.82      0.82      0.82       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('classification report for Logreg with Tvec \\n' + classification_report(y_test,pipe2.predict(test_clean)))\n",
    "print('classification report for Naive Bayes \\n' + classification_report(y_test,pipe3.predict(test_clean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c673d10b",
   "metadata": {},
   "source": [
    "Using the aforementioned criteria of minimizing total accuracy drop and maximizing recall with respect to class 1, I selected the Naive Bayes Multinomial model for deployment for stylescouts.com. While this model performed well in this process, it is worth noting that the Naive Bayes model assumes feature independence which may prove disadvantageous especially for processing text data. In reality, it is near impossible to obtain a dataset with features that are mutually independent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ef7807",
   "metadata": {},
   "source": [
    "<a id='conclude'></a>\n",
    "# Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942d3564",
   "metadata": {},
   "source": [
    "The **Tfidf Vectorization** method is recommended for search engine optimization (SEO) purposes as it penalizes common words that have little predictive value as opposed to Count Vectorization. This emphasize words of higher importance in the predictive task.\n",
    "\n",
    "The **Naive Bayes Multinomial model** was the best performing model out of the 5 in terms of:\n",
    "- Gridsearch and train Accuracy\n",
    "    * Good at making correct predictions\n",
    "- Robustness (test and unseen accuracy drop)\n",
    "    * Good at generalizing to new data (eg. latest trends)\n",
    "- Sensitivity\n",
    "    * Minimize false negatives (predicting male when actually female)\n",
    "    \n",
    "Therefore it is recommended to deploy the above machine learning algorithm for SEO in the stylescout website.\n",
    "\n",
    "Some advantages of using the Naive Bayes model include:\n",
    "- It requires a small amount of training data to estimate the test data. So the training period takes less time.\n",
    "- It can make probabilistic predictions which are interpretable.\n",
    "- It is highly scalable. It scales linearly with the number of predictor features and data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde0ec7f",
   "metadata": {},
   "source": [
    "<a id='future'></a>\n",
    "## Model Limitations and Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003c27a8",
   "metadata": {},
   "source": [
    "### Changes in trends\n",
    "A major limitation to the model is the fact that trends evolve and therefore popular hairstyles change throughout time. \n",
    "\n",
    "One suggestion is to retrain the model each year, using the top posts on the respective subreddits by year, to account for these differences.\n",
    "\n",
    "Another suggestion is to implement deep learning algorithms for unsupervised machine learning to build a more robust model capable of handling new, unlabelled data. This is currently not in the scope of this project and is an area for future work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
