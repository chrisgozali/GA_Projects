{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72573fa1",
   "metadata": {},
   "source": [
    "# Executive Summary\n",
    "\n",
    "Abc network intends to launch a new docu-series on property flipping called \"house hunters\". The show's target audience is Americans who are passionate about transforming homes and reselling them at a profit. Its unique selling point is taking a data driven approach to property flipping. The first season of the series will feature houses in Ames, Iowa. I have been hired as a data scientist to  then idenfity features that are the best predictors of sale prices.\n",
    "\n",
    "By analysing the housing dataset from Ames, Iowa Assessorâ€™s Office containing individual property sales from 2006 - 2010, I have created a predictive model using linear regression with Ridge regularization.  A baseline model describing the average sale price of the entire dataset was used as a benchmark to beat when building the model. To verify that our model works well, we have been provided with a test sample with similar features to the dataset to test on kaggle.\n",
    "\n",
    "This analyses is split in two parts. The first part is for exploratory data anlysis and the second part for model construction and regularization. *This notebook covers the second portion on model construction and regularization.*\n",
    "\n",
    "The model includes a total of 14 features: \n",
    "- 4 continuous\n",
    "- 3 discrete\n",
    "- 3 nominal\n",
    "- 2 ordinal\n",
    "- 2 polynomial\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "The primary stakeholders of this analyses is the team in charge of \"house hunters\" at abc and the secondary stakeholders are American TV viewers who are keen on property flipping. Hence the analyses aims to deconstruct the dataset into digestible information and reduce the features to handful which most strongly predict sale prices, while uncovering interesting relationships between features and sale prices which would help in developing strategies for property flipping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a9e19e",
   "metadata": {},
   "source": [
    "# Additional Comments\n",
    "\n",
    "This notebook contains the final models which were tested after multiple model iterations using different features and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fd5df8",
   "metadata": {},
   "source": [
    "# Contents\n",
    "\n",
    "- [Cleaning the test Dataset](#cleaning)\n",
    "- [Baseline model](#baseline)\n",
    "- [Train/test split](#tts)\n",
    "- [Linear Regression modeling](#lr)\n",
    "- [Ridge regularization](#ridge)\n",
    "- [Lasso regularization](#lasso)\n",
    "- [Elasticnet regularization](#elastic)\n",
    "- [Model comparison](#compare)\n",
    "- [Kaggle Evaluation](#kaggle)\n",
    "- [Results and Conclusions](#results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4a1371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevent libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linspace\n",
    "\n",
    "from sklearn.linear_model import (Ridge, Lasso, ElasticNet, LinearRegression, RidgeCV, LassoCV, ElasticNetCV)\n",
    "from sklearn.model_selection import (train_test_split, cross_val_score, GridSearchCV)\n",
    "from sklearn.preprocessing import (StandardScaler)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6396587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import train dataset\n",
    "df = pd.read_csv('./datasets/train_model_features.csv')\n",
    "\n",
    "#import test dataset\n",
    "df_test = pd.read_csv('./datasets/test.csv')\n",
    "df_test_raw = df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3f3c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6031c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b947c7",
   "metadata": {},
   "source": [
    "<a id='cleaning'></a>\n",
    "# Cleaning the Test dataset\n",
    "\n",
    "\n",
    "## Data dictionary\n",
    "\n",
    "| Feature                  | Datatype | Description                                                                              |\n",
    "|--------------------------|----------|------------------------------------------------------------------------------------------|\n",
    "| gr_liv_area              | int64    | Above grade (ground) living area square feet                                             |\n",
    "| total_bsmt_sf            | int64    | Total square feet of basement area                                                       |\n",
    "| garage_area              | int64    | Size of garage in square feet                                                            |\n",
    "| mas_vnr_area             | float64  | Masonry veneer area in square feet                                                       |\n",
    "| overall_qual             | int64    | Rating for overall material and finish of the house                                      |\n",
    "| fireplace_qu             | int64    | Fireplace quality                                                                        |\n",
    "| age                      | int64    | Age of property since original construction date                                         |\n",
    "| since_reno               | int64    | Number of years since last remodeled                                                     |\n",
    "| tot_baths                | float64  | Total number of bathrooms including basement bathrooms                                   |\n",
    "| neighbor_h               | int64    | Binary feature, 1 indicating that the property is located in an upper class neighborhood |\n",
    "| neighbor_l               | int64    | Binary feature, 1 indicating that the property is located in a lower class neighborhood  |\n",
    "| garage_type_a            | int64    | Binary feature, 1 indicating that the garage is attached or built in to the house.       |\n",
    "| gr_liv_area overall_qual | int64    | Polynomial feature                                                                       |\n",
    "| garage_area overall_qual | int64    | Polynomial feature                                                                       |\n",
    "| saleprice                | int64    | Sale price of property in $                                                              |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5843ff7e",
   "metadata": {},
   "source": [
    "The changes made on the training dataset, including feature engineering, will need to be performed on the test dataset such that it will contain the same column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9af73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns = df_test.columns.map(lambda x: (str(x.replace(' ','_'))).lower())\n",
    "df_test.columns = df_test.columns.map(lambda x: (str(x.replace('/','_'))).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24367db",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['gr_liv_area',\n",
    "             'total_bsmt_sf',\n",
    "             'garage_area',\n",
    "             'mas_vnr_area',\n",
    "             'overall_qual',\n",
    "             'fireplace_qu',\n",
    "             'neighborhood',\n",
    "             'garage_type',\n",
    "             'year_built',\n",
    "             'year_remod_add',\n",
    "             'full_bath',\n",
    "             'bsmt_full_bath',\n",
    "             'half_bath',\n",
    "             'bsmt_half_bath',\n",
    "             'id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668497ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_dict = {'lot_shape': {'Reg':0, 'IR1':1, 'IR2':2, 'IR3':3}, #mapping lot_shape. Ranking represents measure of irregularity\n",
    "               \n",
    "               'utilities': {'AllPub':0, 'NoSewr':1, 'NoSeWa':2, 'ELO':3}, #mapping utilities. Ranking is based on 0 = having all public utilities, 3 = minimum utilities(electricity only) indicating a reduction in quality of life.\n",
    "               \n",
    "               'land_slope': {'Gtl':0, 'Mod':1, 'Sev':2}, #mapping land_slope. Ranking is based on slope severity.\n",
    "                \n",
    "               'exter_qual': {'Po':-4, 'Fa':-2, 'TA':0, 'Gd':2, 'Ex':4}, #mapping exter_qual, kitchen_qual, exter_cond and heating_qc\n",
    "               'kitchen_qual':{'Po':-4, 'Fa':-2, 'TA':0, 'Gd':2, 'Ex':4}, #these 4 variables take a similar ranking where 0 represents typical/average quality\n",
    "               'exter_cond': {'Po':-4, 'Fa':-2, 'TA':0, 'Gd':2, 'Ex':4}, #-ve values indicate quality below average and +ve values indicate quality above average\n",
    "               'heating_qc': {'Po':-4, 'Fa':-2, 'TA':0, 'Gd':2, 'Ex':4}, #magnitude is set as 2 to amplify effects of 'good' and 'fair' quality\n",
    "                \n",
    "               'pool_qc': {'None':0, 'Fa':1, 'TA':2, 'Gd':3, 'Ex':4}, #mapping pool_qc, bsmt_qual, bsmt_cond, fireplace_qu, garage_qual, garage_cond\n",
    "               'bsmt_qual': {'None':0, 'Po':1,'Fa':2,'TA':3, 'Gd':4, 'Ex':5}, #these variables also take a similar ranking\n",
    "               'bsmt_cond': {'None':0, 'Po':1,'Fa':2,'TA':3, 'Gd':4, 'Ex':5}, # 0 represents having no pool/basement/fireplace/garage\n",
    "               'fireplace_qu': {'None':0, 'Po':1,'Fa':2,'TA':3, 'Gd':4, 'Ex':5}, #ranking is in increasing order of quality\n",
    "               'garage_qual': {'None':0, 'Po':1,'Fa':2,'TA':3, 'Gd':4, 'Ex':5},\n",
    "               'garage_cond': {'None':0, 'Po':1,'Fa':2,'TA':3, 'Gd':4, 'Ex':5},\n",
    "                \n",
    "               'bsmt_exposure': {'No':0, 'None':0, 'Mn':1, 'Av':2, 'Gd':3}, #mapping bsmt_exposure. Having no basement and no exposure are considered to be of the same value of 0.\n",
    "                \n",
    "               'bsmtfin_type_1': {'None':0, 'Unf':1,'LwQ':2, 'Rec':3, 'BLQ':4, 'ALQ':5, 'GLQ':6}, #mapping bsmtfin_type_1 bsmtfin_type_2\n",
    "               'bsmtfin_type_2': {'None':0, 'Unf':1,'LwQ':2, 'Rec':3, 'BLQ':4, 'ALQ':5, 'GLQ':6}, #Ranking is based on quality of finish\n",
    "                \n",
    "               'electrical': {'SBrkr':0, 'FuseA':1, 'FuseF':2, 'FuseP':3, 'Mix':2.5}, #mapping electrical. Ranking is based on 0 having standard circuit breakers in in order of decreasing electrical system sophistication. \n",
    "                #Mixed electrical system is considered to be between FuseF and FuseP\n",
    "                \n",
    "               'functional':{'Typ':0,'Min1':1,'Min2':2, 'Mod':3, 'Maj1':4, 'Maj2':5, 'Sev':6, 'Sal':7}, #mapping functional. Ranking is based on 0 having typical home functionality and in decreasing order of functionality\n",
    "                \n",
    "               'garage_finish':{'None':0, 'Unf':1, 'RFn':2, 'Fin':3}, #mapping garage_finish. 0 represents having no garage and ranking is in order of quality of finish.\n",
    "                \n",
    "               'paved_drive':{'N':0, 'P':1, 'Y':2}, #mapping paved_drive. Ranking is in order of amount of paving on driveway.\n",
    "                \n",
    "               'fence':{'None':0, 'MnWw':1, 'GdWo':2, 'MnPrv':3, 'GdPrv':4} #mapping fence. 0 represents having no fence and ranking is in increasing levels of privacy\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fbc6dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#drop null values for columns of interest\n",
    "df_test['fireplace_qu'] = df_test['fireplace_qu'].fillna('None')\n",
    "df_test['mas_vnr_area'] = df_test['mas_vnr_area'].fillna(0)\n",
    "\n",
    "#Ordinal features encoding\n",
    "for i in ordinal_dict:\n",
    "    df_test[i] = df_test[i].map(ordinal_dict[i])\n",
    "\n",
    "#select only the necessary columns\n",
    "df_test = df_test[features]\n",
    "\n",
    "#Discrete feature engineering\n",
    "df_test['age'] = 2010 - df_test['year_built']\n",
    "df_test['since_reno'] = 2010 - df_test['year_remod_add']\n",
    "df_test['tot_baths'] = df_test['full_bath'] + df_test['bsmt_full_bath'] + 0.5*(df_test['half_bath'] + df_test['bsmt_half_bath'])\n",
    "\n",
    "#Drop the original columns\n",
    "df_test.drop(columns = ['year_built',\n",
    "                        'year_remod_add',\n",
    "                        'full_bath',\n",
    "                        'bsmt_full_bath',\n",
    "                        'half_bath',\n",
    "                        'bsmt_half_bath'\n",
    "                       ], inplace = True)\n",
    "\n",
    "#Nominal features mapping\n",
    "\n",
    "df_test['garage_type_a'] = df_test['garage_type'].map(lambda x: 1 if x == 'Attchd' or x == 'BuiltIn' else 0)\n",
    "df_test['neighbor_h'] = df_test['neighborhood'].map(lambda x: 1 if x == 'StoneBr' or x =='NridgHt' or x == 'NoRidge' or x == 'GrnHill' or x == 'Veenker' else 0)\n",
    "df_test['neighbor_l'] = df_test['neighborhood'].map(lambda x: 1 if x == 'BrDale' or x == 'IDOTRR' or x == 'MeadowV' else 0)\n",
    "\n",
    "\n",
    "#Adding polynomial interactions\n",
    "df_test['gr_liv_area overall_qual'] = df_test['gr_liv_area'] * df_test['overall_qual']\n",
    "df_test['garage_area overall_qual'] = df_test['garage_area'] * df_test['overall_qual']\n",
    "\n",
    "#Drop the original columns\n",
    "df_test.drop(columns = ['garage_type',\n",
    "                        'neighborhood'\n",
    "                       ], inplace = True)\n",
    "\n",
    "#Display the resulting model features\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328a1f07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check if null values still present\n",
    "df_test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2433b0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check all dtypes are numerical\n",
    "df_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cdc415",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fceee8",
   "metadata": {},
   "source": [
    "Check that the dimensions of both dataframes match. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bc5dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a83579",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8357c4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9473427e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e515cbea",
   "metadata": {},
   "source": [
    "Note that the train dataframe has an extra column `saleprice` and the test dataframe has an extra column `id`. Now our features match and we can proceed to modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0307630",
   "metadata": {},
   "source": [
    "# Baseline model\n",
    "<a id='baseline'></a>\n",
    "\n",
    "The baseline model is the most simplistic prediction of saleprice which is based on the overall mean of all the houses in the dataset. This is the model we need to 'beat' to know our model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eaa920",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "baseline = df['saleprice'].mean()\n",
    "baseline = [baseline] * 879"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f39206",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = pd.DataFrame({'Id': df_test_raw['id'],\n",
    "                                 'SalePrice': baseline})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163e1e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model.to_csv('./datasets/baseline_model.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a051e6",
   "metadata": {},
   "source": [
    "The plot for the baseline model is the mean sale price of all the houses in our dataset, which is 181,511. Since we are using kaggle to verify our model performance, we used the baseline model score to set a score to beat. Upon submission to kaggle, we received a root mean square error of 83,689.36!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b19a29",
   "metadata": {},
   "source": [
    "<a id='tts'></a>\n",
    "# Train/test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09713a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'saleprice'\n",
    "model_features = [x for x in df.columns if x != target]\n",
    "\n",
    "X = df[model_features]\n",
    "y = df[target]\n",
    "X_test = df_test\n",
    "\n",
    "X_train, X_holdout, y_train, y_holdout  = train_test_split(X, y, random_state = 26, train_size = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae3ce95",
   "metadata": {},
   "source": [
    "### Scaling features\n",
    "\n",
    "Scaling features is essential when their magnitudes are significantly different from one another. However we must be careful to apply scaling only on non-binary features. Therefore the features `garage_type_a`, `neighbor_h` and `neighbor_l` are left out of the scaling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe27d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e902fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['gr_liv_area', \n",
    "        'total_bsmt_sf', \n",
    "        'garage_area', \n",
    "        'mas_vnr_area', \n",
    "        'overall_qual', \n",
    "        'fireplace_qu',\n",
    "        'age',\n",
    "        'since_reno',  \n",
    "        'tot_baths',\n",
    "        'gr_liv_area overall_qual',\n",
    "        'garage_area overall_qual'\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2883ac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizing predictors\n",
    "ss_X = StandardScaler()\n",
    "\n",
    "for i in cols:\n",
    "    X_train[i] = ss_X.fit_transform(X_train[[i]])\n",
    "    X_holdout[i] = ss_X.transform(X_holdout[[i]])\n",
    "    X_test[i] = ss_X.transform(X_test[[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0979ff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_log = np.log(y_train)\n",
    "y_holdout_log = np.log(y_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313caac7",
   "metadata": {},
   "source": [
    "<a id='lr'></a>\n",
    "# Linear Regression Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79efd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train_log)\n",
    "\n",
    "lr_train_rmse = -cross_val_score(\n",
    "                LinearRegression(),\n",
    "                X_train,\n",
    "                y_train_log,\n",
    "                cv = 10,\n",
    "                scoring = 'neg_root_mean_squared_error').mean()\n",
    "lr_train_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c686d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate predicted values from linear regression model\n",
    "lr_preds = np.exp(lr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a82c1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the model\n",
    "plt.figure(figsize=(12,9))\n",
    "\n",
    "# Generate a scatterplot of predicted values versus actual values.\n",
    "plt.scatter(y_train, lr_preds, s=5, color='red', alpha = 0.5)\n",
    "\n",
    "# Plot a line.\n",
    "plt.plot([0, np.max(y)],\n",
    "         [0, np.max(y)],\n",
    "         color = 'black')\n",
    "\n",
    "# Tweak title and axis labels.\n",
    "plt.ylabel(\"Predicted Values: $\\hat{y}$\", fontsize = 20)\n",
    "plt.xlabel(\"Actual Values: $y$\", fontsize = 20)\n",
    "plt.title('Predicted Values vs. Actual Values', fontsize = 24);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbb255f",
   "metadata": {},
   "source": [
    "The basic linear regression model is able to predict houses of lower saleprices much more accurately than houses of higher saleprices. The model tends to overpredict houses with high saleprices. We also note that there is much more data available for houses of low saleprices. Having more data on houses sold at higher prices might in constructing a better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa29eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store holdout RMSE for comparison later\n",
    "lr_holdout_rmse = -cross_val_score(\n",
    "                LinearRegression(),\n",
    "                X_holdout,\n",
    "                y_holdout_log,\n",
    "                cv = 10,\n",
    "                scoring = 'neg_root_mean_squared_error').mean()\n",
    "lr_holdout_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7f6229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store coefficients for comparison later\n",
    "lr_coefs = pd.DataFrame({'lr_coefs' :lr.coef_})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf25e43",
   "metadata": {},
   "source": [
    "<a id='ridge'></a>\n",
    "# Ridge Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03188232",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ridgecv = RidgeCV(alphas = np.logspace(0,3,1000))\n",
    "ridgecv.fit(X_train,y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71f7480",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimal alpha for ridge regression model is\n",
    "ridgecv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84371611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the ridge regression model on the train data\n",
    "ridge_train_rmse = -cross_val_score(\n",
    "                    Ridge(alpha = ridgecv.alpha_),\n",
    "                    X_train,\n",
    "                    y_train_log,\n",
    "                    cv = 10,\n",
    "                    scoring = 'neg_root_mean_squared_error',).mean()\n",
    "ridge_train_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef866314",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha = ridgecv.alpha_)\n",
    "ridge.fit(X_train, y_train_log)\n",
    "ridge_preds = np.exp(ridgecv.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07e7eea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the model\n",
    "plt.figure(figsize=(12,9))\n",
    "\n",
    "# Generate a scatterplot of predicted values versus actual values.\n",
    "plt.scatter(y_train, ridge_preds, s=5, color='blue', alpha = 0.5)\n",
    "\n",
    "# Plot a line.\n",
    "plt.plot([0, np.max(y)],\n",
    "         [0, np.max(y)],\n",
    "         color = 'black')\n",
    "\n",
    "# Tweak title and axis labels.\n",
    "plt.ylabel(\"Predicted Values: $\\hat{y}$\", fontsize = 20)\n",
    "plt.xlabel(\"Actual Values: $y$\", fontsize = 20)\n",
    "plt.title('Predicted Values vs. Actual Values', fontsize = 24);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881e1df1",
   "metadata": {},
   "source": [
    "The model with ridge regularization behaves similarly to the normal linear regression model in that it overpredicts houses at higher sale prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c566756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store holdout rmse for comparison later\n",
    "ridge_holdout_rmse = -cross_val_score(\n",
    "                    Ridge(alpha = ridgecv.alpha_),\n",
    "                    X_holdout,\n",
    "                    y_holdout_log,\n",
    "                    cv = 10,\n",
    "                    scoring = 'neg_root_mean_squared_error',).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb22f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store coefficients for comparison later\n",
    "ridge_coefs = pd.DataFrame({'ridge_coefs' :ridgecv.coef_})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c14e35",
   "metadata": {},
   "source": [
    "<a id='lasso'></a>\n",
    "# Lasso Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fdf898",
   "metadata": {},
   "outputs": [],
   "source": [
    "lassocv = LassoCV(n_alphas = 500)\n",
    "lassocv.fit(X_train, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9661112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimum alpha\n",
    "lassocv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d45143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test rmse for lasso on train dataset\n",
    "lasso_train_rmse = -cross_val_score(\n",
    "                    Lasso(alpha = lassocv.alpha_),\n",
    "                    X_train,\n",
    "                    y_train_log,\n",
    "                    cv = 10,\n",
    "                    scoring = 'neg_root_mean_squared_error',).mean()\n",
    "lasso_train_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b37bcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store coefficients for comparison later\n",
    "lasso_coefs = pd.DataFrame({'lasso_coefs' :lassocv.coef_})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c7691d",
   "metadata": {},
   "source": [
    "## Lasso Coefficients\n",
    "\n",
    "It is important to check if any of the coefficients tended to 0 with lasso regularization. This helps to eliminate features which do not have much predictive value for the saleprice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5889fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check whether any of the coefficients tended to 0\n",
    "lasso_coefs['zeros'] = lasso_coefs['lasso_coefs'].map(lambda x: 1 if x == 0 else 0)\n",
    "lasso_coefs['zeros'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf6d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha = lassocv.alpha_)\n",
    "lasso.fit(X_train, y_train_log)\n",
    "lasso_preds = np.exp(lasso.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261107ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the model\n",
    "plt.figure(figsize=(12,9))\n",
    "\n",
    "# Generate a scatterplot of predicted values versus actual values.\n",
    "plt.scatter(y_train, lasso_preds, s=5, color='orange', alpha = 0.5)\n",
    "\n",
    "# Plot a line.\n",
    "plt.plot([0, np.max(y)],\n",
    "         [0, np.max(y)],\n",
    "         color = 'black')\n",
    "\n",
    "# Tweak title and axis labels.\n",
    "plt.ylabel(\"Predicted Values: $\\hat{y}$\", fontsize = 20)\n",
    "plt.xlabel(\"Actual Values: $y$\", fontsize = 20)\n",
    "plt.title('Predicted Values vs. Actual Values', fontsize = 24);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a27fd5",
   "metadata": {},
   "source": [
    "The model with lasso regularization behaves similarly to the normal linear regression model in that it overpredicts houses at higher sale prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bcaa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store rmse for comparison later\n",
    "lasso_holdout_rmse = -cross_val_score(\n",
    "                    Lasso(alpha = lassocv.alpha_),\n",
    "                    X_holdout,\n",
    "                    y_holdout_log,\n",
    "                    cv = 10,\n",
    "                    scoring = 'neg_root_mean_squared_error',).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be99322",
   "metadata": {},
   "source": [
    "<a id='elastic'></a>\n",
    "# Elastic Net\n",
    "\n",
    "\n",
    "Elasticnet regularization is a combination of both ridge and lasso regularization. The l1_ratio determines which regularization is more heavily weighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad2d7bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "elastic = ElasticNet()\n",
    "elasticcv = ElasticNetCV(n_alphas = 500,l1_ratio = list(linspace(0.01,0.5,200)))\n",
    "elasticcv.fit(X_train, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78ced99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#elasticnet optimum alpha\n",
    "elasticcv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16d018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#elasticnet optimum l1 ratio\n",
    "elasticcv.l1_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d4501d",
   "metadata": {},
   "source": [
    "The l1 ratio for elasticnet regularization tells us how much the model leans towards lasso regularization. As shown by the optimum l1 ratio, the elasticnet model uses mostly ridge regularization and has minimal penalties from lasso regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbae984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic = ElasticNet(alpha = elasticcv.alpha_, l1_ratio = elasticcv.l1_ratio_)\n",
    "elastic_train_rmse = -cross_val_score(\n",
    "                    elastic,\n",
    "                    X_train,\n",
    "                    y_train_log,\n",
    "                    cv = 10,\n",
    "                    scoring = 'neg_root_mean_squared_error',).mean()\n",
    "elastic_train_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdca17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic = ElasticNet(alpha = elasticcv.alpha_, l1_ratio = elasticcv.l1_ratio_)\n",
    "elastic.fit(X_train, y_train_log)\n",
    "elastic_preds = np.exp(elastic.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253e63c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the model\n",
    "plt.figure(figsize=(12,9))\n",
    "\n",
    "# Generate a scatterplot of predicted values versus actual values.\n",
    "plt.scatter(y_train, elastic_preds, s=5, color='green', alpha = 0.5)\n",
    "\n",
    "# Plot a line.\n",
    "plt.plot([0, np.max(y)],\n",
    "         [0, np.max(y)],\n",
    "         color = 'black')\n",
    "\n",
    "# Tweak title and axis labels.\n",
    "plt.ylabel(\"Predicted Values: $\\hat{y}$\", fontsize = 20)\n",
    "plt.xlabel(\"Actual Values: $y$\", fontsize = 20)\n",
    "plt.title('Predicted Values vs. Actual Values', fontsize = 24);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b90fb62",
   "metadata": {},
   "source": [
    "The model with elasticnet regularization behaves similarly to the normal linear regression model in that it overpredicts houses at higher sale prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f30edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store rmse for comparison later\n",
    "elastic_holdout_rmse = -cross_val_score(\n",
    "                        elastic,\n",
    "                        X_holdout,\n",
    "                        y_holdout_log,\n",
    "                        cv = 10,\n",
    "                        scoring = 'neg_root_mean_squared_error',).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebabccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store coefficients for comparison later\n",
    "elastic_coefs = pd.DataFrame({'elastic_coefs' :elasticcv.coef_})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d2b827",
   "metadata": {},
   "source": [
    "<a id='compare'></a>\n",
    "# Comparisons between models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11055112",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = pd.DataFrame ( [lr_train_rmse,\n",
    "                     lr_holdout_rmse,\n",
    "                     ridge_train_rmse,\n",
    "                     ridge_holdout_rmse,\n",
    "                     lasso_train_rmse,\n",
    "                     lasso_holdout_rmse,\n",
    "                     elastic_train_rmse,\n",
    "                     elastic_holdout_rmse], \n",
    "                     index = ['lr_train_rmse',\n",
    "                     'lr_holdout_rmse',\n",
    "                     'ridge_train_rmse',\n",
    "                     'ridge_holdout_rmse',\n",
    "                     'lasso_train_rmse',\n",
    "                     'lasso_holdout_rmse',\n",
    "                     'elastic_train_rmse',\n",
    "                     'elastic_holdout_rmse'])\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f30ea55",
   "metadata": {},
   "source": [
    "The root mean squared error for the predicted log sale prices is the smallest for ridge regularization, indicating that our model with ridge regularization is the best predictor for saleprices. We can explore the coefficients for our models for more insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbe73bb",
   "metadata": {},
   "source": [
    "## Interpreting intercept and coefficients\n",
    "\n",
    "The intercept and coefficients obtained are for a log transformed linear regression model and do not represent a direct linear relationship to the sale price. Instead, the way to interpret these is as follows: The exponentiated value of the intercepts represents the geometric mean of the saleprice. The coefficients represent a % increase in the saleprice for increase in 1 unit of feature X. For negative values, it represents a % decrease in saleprice for a 1 unit increase of feature X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eace03",
   "metadata": {},
   "outputs": [],
   "source": [
    "colums = pd.DataFrame(X_train.columns, columns = ['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31758c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pd.concat([colums, lr_coefs,ridge_coefs,lasso_coefs.drop(columns = 'zeros'),elastic_coefs], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e33a77a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coefficients.set_index('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248461a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "intercepts = pd.DataFrame({'lr_intercept': [lr.intercept_],\n",
    "                          'ridge_intercept': [ridge.intercept_],\n",
    "                          'lasso_intercept': [lasso.intercept_],\n",
    "                          'elasticnet_intercept': [elastic.intercept_]})\n",
    "intercepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32e7d96",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize =(8,5))\n",
    "sns.barplot(data = coefficients, x = 'lr_coefs', y = 'features');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca58914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize =(8,5))\n",
    "sns.barplot(data = coefficients, x = 'ridge_coefs', y = 'features');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0f484e",
   "metadata": {},
   "source": [
    "The coefficients for the lasso and regular regression model do not change by much, indicating that the model is not penalized much for variance.\n",
    "\n",
    "As seen from the results, the strongest predictors of saleprice is the`overall_qual`, `gr_liv_area`, `neighbor_l` and `since_reno`. The weakest predictors are `mas_vnr_area` and `age`.\n",
    "\n",
    "Ridge regularization amplifies the predictive value of the polynomial features as compared to the regular regression model. It also amplifies `garage_area`, `total_bsmt_sf`, `since_reno` and `garage type_a`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22c4894",
   "metadata": {},
   "source": [
    "<a id='kaggle'></a>\n",
    "# Kaggle Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e544fd90",
   "metadata": {},
   "source": [
    "We will retrain the model on the full training set using ridge regularization to ensure that the model utilises the maximum amount of data available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd5bae3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ss_X = StandardScaler()\n",
    "\n",
    "X_full_train = X\n",
    "for i in cols:\n",
    "    \n",
    "    X_full_train[i] = ss_X.fit_transform(X[[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342bcb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log = np.log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365d6bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.drop(columns = 'id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705d52ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ridgecv = RidgeCV(alphas = np.logspace(0,3,1000))\n",
    "ridgecv.fit(X_full_train,y_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e6722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgecv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777c99f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha = ridgecv.alpha_)\n",
    "ridge.fit(X_full_train, y_log)\n",
    "test_preds = np.exp(ridge.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6ef971",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b43ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submission = pd.DataFrame({'Id': df_test_raw['id'],\n",
    "                                 'SalePrice': test_preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7544a26f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kaggle_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3b18b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submission.to_csv('./datasets/kaggle_submission_final.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72101bd",
   "metadata": {},
   "source": [
    "<a id='results'></a>\n",
    "# Results and conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d12032b",
   "metadata": {},
   "source": [
    "Upon testing our model against the test dataset of 879 houses, we received a root mean squared error of 26,502.87. This is a great improvement from our baseline score of 83,689.36!\n",
    "\n",
    "The features we selected from the original dataset prove as valuable predictors of house saleprices. The features which lead to the best increases in sale prices are `overall_qual`, `gr_liv_area`, `neighbor_l` and `since_reno`. With some interesting features such as `fireplace_qu`, `tot_baths`, `garage_area` and `garage_type_a`.\n",
    "\n",
    "Houseflipping often involves renovating a property and selling it at a higher price. As seen from our model, it is logical that an increase in the property's overall quality(`overall_qual`). Newly renovated houses also tend to fetch a higher selling price (`since_reno`).\n",
    "\n",
    "However some interesting trends picked up highlighted the potential impact of improving the quality of fireplaces `fireplace_qu`, and having a garage built in or attached to the house (`garage_type_a`).\n",
    "\n",
    "The strong negative coefficient for `neighbor_l` suggests that Iowa DOT & Rail Road, Briardale and Meadow Village are areas that do not tend to fetch high house prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa0abdd",
   "metadata": {},
   "source": [
    "## Recommendations to stakeholders\n",
    "\n",
    "I would recommend \"house hunters\" to avoid the neighborhoods in `neighbor_l` in their search for potential houses to flip. When selecting houses, look out for the potential to add an in-built or attached garage to the house. During the renovation, it would be beneficial to improve the quality of the fireplace or add one if there is none. Winters can get really cold in Ames!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cebdce",
   "metadata": {},
   "source": [
    "## Future work\n",
    "\n",
    "Our model showed less predictive accuracy for more the more expensive properties as compared to the ones which were lower priced. This can be improved upon by including more data for expensive houses sold."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
