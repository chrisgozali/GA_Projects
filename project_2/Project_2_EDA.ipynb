{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab39b12c",
   "metadata": {},
   "source": [
    "# Executive Summary\n",
    "\n",
    "Abc network intends to launch a new docu-series on property flipping called \"house hunters\". The show's target audience is Americans who are passionate about transforming homes and reselling them at a profit. Its unique selling point is taking a data driven approach to property flipping. The first season of the series will feature houses in Ames, Iowa. I have been hired as a data scientist to  then idenfity features that are the best predictors of sale prices.\n",
    "\n",
    "By analysing the housing dataset from Ames, Iowa Assessorâ€™s Office containing individual property sales from 2006 - 2010, I have created a predictive model using linear regression with Ridge regularization.  A baseline model describing the average sale price of the entire dataset was used as a benchmark to beat when building the model. To verify that our model works well, we have been provided with a test sample with similar features to the dataset to test on kaggle.\n",
    "\n",
    "This analyses is split in two parts. The first part is for exploratory data anlysis and the second part for model construction and regularization. *This notebook covers the first part on EDA.*\n",
    "\n",
    "The model includes a total of 14 features: \n",
    "- 4 continuous\n",
    "- 3 discrete\n",
    "- 3 nominal\n",
    "- 2 ordinal\n",
    "- 2 polynomial\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "The primary stakeholders of this analyses is the team in charge of \"house hunters\" at abc and the secondary stakeholders are American TV viewers who are keen on property flipping. Hence the analyses aims to deconstruct the dataset into digestible information and reduce the features to handful which most strongly predict sale prices, while uncovering interesting relationships between features and sale prices which would help in developing strategies for property flipping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367db6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linspace\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab6019c",
   "metadata": {},
   "source": [
    "# Contents\n",
    "\n",
    "- [Data Cleaning and Processing](#cleaning)\n",
    "    - [Addressing Null Values](#null)\n",
    "    - [Outliers](#outliers)\n",
    "\n",
    "- [Exploratory Data Analysis](#eda)\n",
    "    - [Continuous Features](#cont)\n",
    "    - [Discrete Features](#disc)\n",
    "    - [Ordinal Features](#ordi)\n",
    "    - [Nominal Features](#nomi)\n",
    "    - [Polynomial Features](#poly)\n",
    "    - [Target Feature](#target)\n",
    "- [Selected Features](#select)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e1dfad",
   "metadata": {},
   "source": [
    "# Data Cleaning and Processing\n",
    "<a id='cleaning'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31abc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import train dataset\n",
    "train_df = pd.read_csv('./datasets/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0f838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#General function for checking dataframe\n",
    "def df_checks (df):\n",
    "    print('Dataframe dimensions: \\n' + str(df.shape) + '\\n')\n",
    "    print('Column Names:')\n",
    "    print(df.columns)\n",
    "    print('\\n')\n",
    "    print('Missing Values: \\n' + str(df.isnull().sum().sort_values(ascending = False).head(10)) + '\\n')\n",
    "    print('Statistics: \\n' + str(df.describe()) + '\\n')\n",
    "    print('Datatypes: \\n' + str(df.dtypes) + '\\n')\n",
    "    print('Information: \\n')\n",
    "    print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7611a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_checks(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f4b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new dataframe to store clean data\n",
    "train_clean = train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4ef3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make changes to column names for convenience\n",
    "\n",
    "train_clean.columns = train_clean.columns.map(lambda x: (str(x.replace(' ','_'))).lower())\n",
    "train_clean.columns = train_clean.columns.map(lambda x: (str(x.replace('/','_'))).lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba7779c",
   "metadata": {},
   "source": [
    "## Summary of train dataset\n",
    "Total of 81 features and 2051 rows in the dataset. The tables below summarize the features by their types along with their description and missing values.\n",
    "\n",
    "### Target feature: 1\n",
    "\n",
    "|No|Column name|Data type|Description|Null values|\n",
    "|:---:|:---|:---:|---|---:|\n",
    "|1|saleprice|int|Sale price of property in $|0|\n",
    "\n",
    "### Continuous features: 19\n",
    "\n",
    "|No|Column name|Data type|Description|Null values|\n",
    "|:---:|:---|:---:|---|---:|\n",
    "|1|lot_frontage|float|Linear feet of street connected to property|330|\n",
    "|2|lot_area|int|Lot size in square feet|0|\n",
    "|3|mas_vnr_area|float|Masonry veneer area in square feet|22|\n",
    "|4|basmtfin_sf_1|float|Type 1 basement area in square feet|1|\n",
    "|5|basmtfin_sf_2|float|Type 2 basement area in square feet|1|\n",
    "|6|bsmt_unf_sf|float|Unfinished basement area in square feet|1|\n",
    "|7|total_bsmt_sf|float|Total square feet of basement area|1|\n",
    "|8|1st_flr_sf|int|First floor area in square feet|0|\n",
    "|9|2nd_flr_sf|int|Second floor area in square feet|0|\n",
    "|10|low_qual_fin_sf|int|Low quality finished in square feet (all floors)|0|\n",
    "|11|gr_liv_area|int|Above grade (ground) living area square feet|0|\n",
    "|12|garage_area|float|Size of garage in square feet|1|\n",
    "|13|wood_deck_sf|int|Wood deck area in square feet|0|\n",
    "|14|open_porch_sf|int|Open porch area in square feet|0|\n",
    "|15|enclosed_porch|int|Enclosed porch area in square feet|0|\n",
    "|16|3ssn_porch|int|Three season porch area in square feet|0|\n",
    "|17|screen_porch|int|Screen porch area in square feet|0|\n",
    "|18|pool_area|int|Pool area in square feet|0|\n",
    "|19|misc_val|int|Value of miscellaneous feature in $|0|\n",
    "\n",
    "\n",
    "### Discrete features: 14\n",
    "\n",
    "|No|Column name|Data type|Description|Null values|\n",
    "|:---:|:---|:---:|---|---:|\n",
    "|1|year_built|int|Original construction date|0|\n",
    "|2|year_remod_add|int|Remodel date (same as construction date if no remodeling or additions)|0|\n",
    "|3|bsmt_full_bath|float|Basement full bathrooms|2|\n",
    "|4|bsmt_half_bath|float|Basement half bathrooms|2|\n",
    "|5|full_bath|int|Full bathrooms above grade|0|\n",
    "|6|half_bath|int|Half baths above grade|0|\n",
    "|7|bedroom_abvgr|int|Bedrooms above grade (does NOT include basement bedrooms)|0|\n",
    "|8|kitchen_abvgr|int|Kitchens above grade|0|\n",
    "|9|totrms_abvgrd|int|Total rooms above grade (does not include bathrooms)|0|\n",
    "|10|fireplaces|int|Number of fireplaces|0|\n",
    "|11|garage_yr_blt|float|Year garage was built|114|\n",
    "|12|garage_cars|float|Garage car capacity|1|\n",
    "|13|mo_sold|int|Month Sold (MM)|0|\n",
    "|14|yr_sold|int|Year Sold (YYYY)|0|\n",
    "\n",
    "### Nominal features: 24\n",
    "\n",
    "|No|Column name|Data type|Description|Null values|\n",
    "|:---:|:---|:---:|---|---:|\n",
    "|1|ms_subclass|int|Identifies the type of dwelling involved in the sale|0|\n",
    "|2|ms_zoning|str|Identifies the general zoning classification of the sale.|0|\n",
    "|3|street|str|Type of road access to property|0|\n",
    "|4|alley|str|Type of alley access to property|1911|\n",
    "|5|land_contour|str|Flatness of the property|0|\n",
    "|6|lot_config|str|Lot configuration|0|\n",
    "|7|neighborhood|str|Physical locations within Ames city limits (map available)|0|\n",
    "|8|condition_1|str|Proximity to various conditions|0|\n",
    "|9|condition_2|str|Proximity to various conditions (if more than one is present)|0|\n",
    "|10|bldg_type|str|Type of dwelling|0|\n",
    "|11|house_style|str|Style of dwelling|0|\n",
    "|12|roof_style|str|Type of roof|0|\n",
    "|13|root_matl|str|Roof material|0|\n",
    "|14|exterior_1st|str|Exterior covering on house|0|\n",
    "|15|exterior_2nd|str|Exterior covering on house (if more than one material)|0|\n",
    "|16|mas_vnr_type|str|Masonry veneer type|22|\n",
    "|17|foundation|str|Type of foundation|0|\n",
    "|18|heating|str|Type of heating|0|\n",
    "|19|central_air|str|Central air conditioning|0|\n",
    "|20|garage_type|str|Garage location|113|\n",
    "|21|misc_feature|str|Miscellaneous feature not covered in other categories|1986|\n",
    "|22|sale_type|str|Type of sale|0|\n",
    "|23|pid|int|parcel indentification number|0|\n",
    "|24|id|int|unique identification number|0|\n",
    "\n",
    "### Ordinal features: 23\n",
    "\n",
    "|No|Column name|Data type|Description|Null values|\n",
    "|:---:|:---|:---:|---|---:|\n",
    "|1|lot_shape|str|General shape of property|0|\n",
    "|2|utilities|str|Type of utilities available|0|\n",
    "|3|land_slope|str|Slope of property|0|\n",
    "|4|overall_qual|int|Rating for overall material and finish of the house|0|\n",
    "|5|overall_cond|int|Ratiing for overall condition of the house|0|\n",
    "|6|exter_qual|str|Evaluates the quality of the material on the exterior|0|\n",
    "|7|exter_cond|str|Evaluates the present condition of the material on the exterior|0|\n",
    "|8|bsmt_qual|str|Evaluates height of basement|55|\n",
    "|9|bsmt_cond|str|Evaluates the general condition of the basement|55|\n",
    "|10|bsmt_exposure|str|Refers to walkout or garden level walls|58|\n",
    "|11|bsmtfin_type_1|str|Rating of basement finished area|55|\n",
    "|12|bsmtfin_type_2|str|Rating of basement finished area (if multiple types)|56|\n",
    "|13|heatingqc|str|Heating quality and condition|0|\n",
    "|14|electrical|str|Electrical system|0|\n",
    "|15|kitchen_qual|str|Kitchen quality|0|\n",
    "|16|functional|str|Home functionality (Assume typical unless deductions are warranted)|0|\n",
    "|17|fireplace_qu|str|Fireplace quality|1000|\n",
    "|18|garage_finish|str| Interior finish of the garage|114|\n",
    "|19|garage_qual|str|Garage quality|114|\n",
    "|20|garage_cond|str|Garage condition|114|\n",
    "|21|paved_drive|str|Paved driveway|0|\n",
    "|22|pool_qc|str|Pool quality|2042|\n",
    "|23|fence|str|Fence quality|1651|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99996440",
   "metadata": {},
   "source": [
    "<a id='null'></a>\n",
    "## Addressing null values\n",
    "\n",
    "There are a total of 26 features with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e9ab50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_clean.isnull().sum().sort_values(ascending = False).head(27)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9d0c1c",
   "metadata": {},
   "source": [
    "Continuous Variables: 7\n",
    "\n",
    "|Column|Null values|\n",
    "|---|---|\n",
    "|lot_frontage|330|\n",
    "|mas_vnr_area|22|\n",
    "|total_bsmt_sf|1|\n",
    "|bsmt_unf_sf|1|\n",
    "|bsmtfin_sf_2|1|\n",
    "|bsmtfin_sf_1|1|\n",
    "|garage_area|1|\n",
    "\n",
    "Discrete Variables: 4\n",
    "\n",
    "|Column|Null values|\n",
    "|---|---|\n",
    "|garage_yr_blt|114|\n",
    "|bsmt_half_bath|2|\n",
    "|bsmt_full_bath|2|\n",
    "|garage_cars|1|\n",
    "\n",
    "\n",
    "Nominal Variables: 4\n",
    "\n",
    "|Column|Null values|\n",
    "|---|---|\n",
    "|misc_feature|1986|\n",
    "|alley|1911|\n",
    "|garage_type|113|\n",
    "|mas_vnr_type|22|\n",
    "\n",
    "\n",
    "\n",
    "Ordinal Varibales: 11\n",
    "\n",
    "|Column|Null values|\n",
    "|---|---|\n",
    "|pool_qc|2042|\n",
    "|fence|1651|\n",
    "|fireplace_qu|1000|\n",
    "|garage_finish|114|\n",
    "|garage_qual|114|\n",
    "|garage_cond|114|\n",
    "|bsmt_exposure|58|\n",
    "|bsmtfin_type_2|56|\n",
    "|bsmtfin_type_1|55|\n",
    "|bsmt_cond|55|\n",
    "|bsmt_qual|55|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9efb64",
   "metadata": {},
   "source": [
    "### Garage Data\n",
    "There is a similar number of null values for garage data. This leads to my hypothesis that the missing garage data is due to house having no garage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b92e0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_garage = train_clean[train_clean['garage_finish'].isnull() == True]\n",
    "missing_garage[['garage_area','garage_yr_blt','garage_cars','garage_type','garage_qual','garage_cond']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4bf24c",
   "metadata": {},
   "source": [
    "Since the `garage_area` and `garage_cars` are `0` for rows with null values for the other garage features, we can safely assume that my hypothesis is true and edit the dataset by replacing the null values with `None` or `0`. For `garage_yr_blt`, it would be safe to impude the year which the house was built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6fd03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean['garage_finish'] = train_clean['garage_finish'].fillna('None')\n",
    "train_clean['garage_area'] = train_clean['garage_area'].fillna(0)\n",
    "train_clean['garage_yr_blt'] = train_clean['garage_yr_blt'].fillna(train_clean['year_built'])\n",
    "train_clean['garage_cars'] = train_clean['garage_cars'].fillna(0)\n",
    "train_clean['garage_type'] = train_clean['garage_type'].fillna('None')\n",
    "train_clean['garage_qual'] = train_clean['garage_qual'].fillna('None')\n",
    "train_clean['garage_cond'] = train_clean['garage_cond'].fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780190e2",
   "metadata": {},
   "source": [
    "### Basement Data\n",
    "I form a similar hypothesis for null values in basement features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d393df",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_basement = train_clean[train_clean['bsmt_exposure'].isnull() == True]\n",
    "missing_basement[['total_bsmt_sf','bsmt_unf_sf','bsmtfin_sf_2','bsmtfin_sf_1','bsmt_half_bath','bsmt_full_bath','bsmtfin_type_2','bsmtfin_type_1','bsmt_cond','bsmt_qual']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9df8cb",
   "metadata": {},
   "source": [
    "We can safely assume that the null values for basement features represent the house having no basement, inluding `bsmt_full_bath` and `bsmt_half_bath`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321daa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean['bsmt_exposure'] = train_clean['bsmt_exposure'].fillna('None')\n",
    "train_clean['total_bsmt_sf'] = train_clean['total_bsmt_sf'].fillna(0)\n",
    "train_clean['bsmt_unf_sf'] = train_clean['bsmt_unf_sf'].fillna(0)\n",
    "train_clean['bsmtfin_sf_2'] = train_clean['bsmtfin_sf_2'].fillna(0)\n",
    "train_clean['bsmtfin_sf_1'] = train_clean['bsmtfin_sf_1'].fillna(0)\n",
    "train_clean['bsmt_half_bath'] = train_clean['bsmt_half_bath'].fillna(0)\n",
    "train_clean['bsmt_full_bath'] = train_clean['bsmt_full_bath'].fillna(0)\n",
    "train_clean['bsmtfin_type_2'] = train_clean['bsmtfin_type_2'].fillna('None')\n",
    "train_clean['bsmtfin_type_1'] = train_clean['bsmtfin_type_1'].fillna('None')\n",
    "train_clean['bsmt_cond'] = train_clean['bsmt_cond'].fillna('None')\n",
    "train_clean['bsmt_qual'] = train_clean['bsmt_qual'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean.isnull().sum().sort_values(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491dab1d",
   "metadata": {},
   "source": [
    "### Other features with null values\n",
    "There are still 8 features remaining containing null values. These will be dealt with individually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854fee2c",
   "metadata": {},
   "source": [
    "#### Pools\n",
    "`pool_qc` is an ordinal feature with values representing the quality of the pool. Its possible values are a rating system (no pool, fair, typical, good, excellent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16793d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean['pool_qc'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34526c6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_pool = train_clean[train_clean['pool_qc'].isnull() == True]\n",
    "missing_pool[['pool_area','pool_qc']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e5064e",
   "metadata": {},
   "source": [
    "We can see that the null values represent the house having no pool. Also, the unique values in the dataset exclude the \"no pool\" rating. Therefore it would be safe to replace the null values with `None` for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf06b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean['pool_qc'] = train_clean['pool_qc'].fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76cbc04",
   "metadata": {},
   "source": [
    "#### Misc Features\n",
    "misc_feature is a nominal feature which represents other features that are not covered by others. In this particular dataset, the misc features includes: elevator, 2nd garage, other, shed, tennis court, none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba9465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean['misc_feature'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de166695",
   "metadata": {},
   "source": [
    "We can safely assume that the null values here represent the house having no additional features. It would be safe to replace the null values with `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e12082",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean['misc_feature'] = train_clean['misc_feature'].fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00596ea",
   "metadata": {},
   "source": [
    "#### Alleys\n",
    "`alley` is a nominal feature which dictates the type of alley access to the property. The feature includes values which represent: gravel, paved, or no alley."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068aaa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean['alley'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96185adc",
   "metadata": {},
   "source": [
    "We can safely assume that the null values here represent the house having no alley access. It would be safe to replace the null values with `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b43be87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean['alley'] = train_clean['alley'].fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca2983f",
   "metadata": {},
   "source": [
    "#### Fences\n",
    "`fence` is an ordinal feature which represents the quality of the fence. The feature describes the fences of the property as having: good privacy, minimum privacy, good wood,  minimum wood/wire, or no fence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bda9a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean['fence'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dac9d2c",
   "metadata": {},
   "source": [
    "We can safely assume that the null values here represent the house having no fence. It would be safe to replace the null values with `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e744a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean['fence'] = train_clean['fence'].fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3328ba",
   "metadata": {},
   "source": [
    "#### Fireplaces\n",
    "`fireplace_qu` is an ordinal variable representing the fireplace quality. The feature includes a rating system in ascending order: no fireplace, poor, fair, average, good and excellent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb79ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean['fireplace_qu'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a358a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_fire = train_clean[train_clean['fireplace_qu'].isnull() == True]\n",
    "missing_fire[['fireplaces','fireplace_qu']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b859bc",
   "metadata": {},
   "source": [
    "Checking `fireplace_qu` against the number of fireplaces confirms that the null values represent missing fireplace. We can safely replace the null values with `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0925f7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean['fireplace_qu'] = train_clean['fireplace_qu'].fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858346ce",
   "metadata": {},
   "source": [
    "#### Masonry\n",
    "The features `mas_vnr_type` and `mas_vnr_area` represent the masonry veneer type and area respectively. The former is a nominal variable taking up different values representing the material used in its construction and the latter represents its size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff26299",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean['mas_vnr_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab794b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_mas = train_clean[train_clean['mas_vnr_type'].isnull() == True]\n",
    "missing_mas[['mas_vnr_type','mas_vnr_area']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b13657",
   "metadata": {},
   "source": [
    "Since the null values for `mas_vnr_type` and `mas_vnr_type` coincide, we can assume that the null represents an absence of masonry veneer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b418c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean['mas_vnr_type'] = train_clean['mas_vnr_type'].fillna('None')\n",
    "train_clean['mas_vnr_area'] = train_clean['mas_vnr_area'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce06518",
   "metadata": {},
   "source": [
    "#### Lot Frontage\n",
    "`lot_frontage` is a continuous feature which refers to the distance between street to property in feet. We must be careful when dealing with the null values for this feature as we do not want the imputation to affect the train/test split. The number of null values is significant here (330) therefore simply replacing them with `0` may not be an accurate representation of the missing values.\n",
    "\n",
    "For EDA purposes I will temporarily fill these values appropriately. If the feature is selected for the model, the changes will be performed again based only on the train dataset.\n",
    "\n",
    "A quick way to resolve this issue is to replace the null values with the overall mean `lot_frontage` of the rest of the dataset. However, it would be more accurate to replace the null values with the mean `lot_frontage` of their respective neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d5498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "sns.boxplot(y= train_clean['neighborhood'], x= train_clean['lot_frontage']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e51e17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean.groupby('neighborhood')['lot_frontage'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409ba153",
   "metadata": {},
   "source": [
    "There is not additional information on the neighborhoods `GrnHill` and `Landmrk` on `lot_frontage`. We will replace those with the overall mean lot_frontage before impudation instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e97da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_mean_frontage = train_clean['lot_frontage'].mean()\n",
    "train_clean['lot_frontage'] = train_clean.groupby('neighborhood')['lot_frontage'].transform(lambda x: x.fillna(x.mean()))\n",
    "train_clean['lot_frontage'] = train_clean['lot_frontage'].fillna(overall_mean_frontage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03671315",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ea56c1",
   "metadata": {},
   "source": [
    "Now we have no more null values!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550161ea",
   "metadata": {},
   "source": [
    "## Checking Data types\n",
    "\n",
    "The features can be categorised into continuous, discrete, nominal and ordinal. We expect continuous and discrete features to be integer or float datatypes.\n",
    "Nominal features should be object or category datatype\n",
    "Ordinal features can be integer/float or object/category datatypes as it depends on the ranking method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a044deee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1ce5d8",
   "metadata": {},
   "source": [
    "The only feature which does not match its datatype as per category is `ms_subclass`. It is an integer when it is a nominal feature. This must be changed to a categorical datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6199c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing dtype for ms_subclass\n",
    "train_clean['ms_subclass'] = train_clean['ms_subclass'].astype(dtype = 'category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ecdc2d",
   "metadata": {},
   "source": [
    "<a id='outliers'></a>\n",
    "## Outliers\n",
    "\n",
    "One final step before we proceed to EDA is dealing with outlier data. In the documentation for the Ames Housing Dataset, it is stated under SPECIAL NOTES that there are some unusual sales which turn out to be outliers. It is also recommended that these outliers are removed before modeling. We can visualize the outliers by plotting `gr_liv_area` vs `saleprice`, then plotting a vertical line to distinguish houses over 4000 sq ft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54236a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,15))\n",
    "sns.scatterplot(data = train_clean, x = 'gr_liv_area', y = 'saleprice');\n",
    "plt.axvline(4000, 0,600000, ls = '--', lw = 1, c = 'black');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b7d099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Locating the outliers based on living area\n",
    "train_clean[(train_clean['gr_liv_area'] >= 4000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631242ce",
   "metadata": {},
   "source": [
    "Additionally, two other outliers were identified during the modeling process. The model over predicted the sale prices of these two houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f20315b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out_1 = pd.DataFrame(train_clean.iloc[125,:])\n",
    "out_2 = pd.DataFrame(train_clean.iloc[348,:])\n",
    "outliers = pd.concat([out_1,out_2], axis = 1)\n",
    "outliers = outliers.T\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27edfcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers['overall_qual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055088d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the 2 outliers\n",
    "train_clean = train_clean.drop([960,1885,125,348]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e8c11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2825fd98",
   "metadata": {},
   "source": [
    "After cleaning, 4 entries have been removed from the dataset and we are left with 2047 rows for 81 features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6f6dfe",
   "metadata": {},
   "source": [
    "<a id='eda'></a>\n",
    "# Exploratory Data Analysis\n",
    "\n",
    "We will conduct EDA by grouping features into their respecive data types to allow for cross examination between features of similar type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc81403",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df630871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us categorize our target and features\n",
    "target = 'saleprice'\n",
    "\n",
    "cont_features = ['lot_frontage','lot_area','mas_vnr_area',\n",
    "                 'bsmtfin_sf_1','bsmtfin_sf_2','bsmt_unf_sf',\n",
    "                 'total_bsmt_sf','1st_flr_sf','2nd_flr_sf',\n",
    "                 'low_qual_fin_sf','gr_liv_area','garage_area',\n",
    "                 'wood_deck_sf','open_porch_sf','enclosed_porch',\n",
    "                 '3ssn_porch','screen_porch','pool_area','misc_val']\n",
    "\n",
    "disc_features = ['year_built','year_remod_add','bsmt_full_bath',\n",
    "                 'bsmt_half_bath','full_bath','half_bath','bedroom_abvgr',\n",
    "                 'kitchen_abvgr','totrms_abvgrd','fireplaces','garage_yr_blt',\n",
    "                 'garage_cars','mo_sold','yr_sold']\n",
    "\n",
    "nomi_features = ['ms_subclass','ms_zoning','street','alley',\n",
    "                 'land_contour','lot_config','neighborhood',\n",
    "                 'condition_1','condition_2','bldg_type','house_style',\n",
    "                 'roof_style','roof_matl','exterior_1st','exterior_2nd',\n",
    "                 'mas_vnr_type','foundation','heating','central_air',\n",
    "                 'garage_type','misc_feature','sale_type']\n",
    "\n",
    "#We take out id and pid for the EDA as they represent a unique identification number and have no predictive value.\n",
    "ordi_features = [x for x in train_clean.columns if x not in ([target] + cont_features + disc_features + nomi_features + ['id','pid'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608fc077",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be59443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ddefaf8",
   "metadata": {},
   "source": [
    "## Overview of correlations between saleprice and numerical features\n",
    "\n",
    "The heatmap between all numerical features is plotted with the column in relation to saleprice in focus. This will help direct our focus to specific features that have a strong relationship to the saleprice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8f3617",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,25))\n",
    "data = train_clean\n",
    "sns.heatmap(data.corr()[['saleprice']].sort_values('saleprice',ascending=False), cmap = 'coolwarm', annot = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1ed8b8",
   "metadata": {},
   "source": [
    "<a id='cont'></a>\n",
    "## Continuous Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7a20ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00566b33",
   "metadata": {},
   "source": [
    "### Continuous features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5692db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#examine correlations between continuous features and target\n",
    "plt.figure(figsize=(12,12))\n",
    "data = train_clean[[target] + cont_features]\n",
    "#mask = np.triu(data.corr())\n",
    "sns.heatmap(data.corr()[['saleprice']].sort_values('saleprice',ascending=False), annot = True, cmap = 'coolwarm');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f37a010",
   "metadata": {},
   "source": [
    "First we examine the correlations of the continuous features with the target. Those that exhibit strong correlations (>0.5) include:\n",
    "\n",
    "- `gr_liv_area`\n",
    "- `total_bsmt_sf`\n",
    "- `garage_area`\n",
    "- `1st_flr_sf`\n",
    "- `mas_vnr_area`\n",
    "\n",
    "Note that there are are many continuous features and of these features exhibit moderate correlations with one another, indicating collinearity.\n",
    "\n",
    "Let's take a closer look at the features and see if we can reduce the noise/complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2506491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean[cont_features].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e9daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#examine correlations between continuous features and target\n",
    "plt.figure(figsize=(12,12))\n",
    "data = train_clean[[target] + cont_features]\n",
    "#mask = np.triu(data.corr())\n",
    "sns.heatmap(data.corr()[['gr_liv_area']].sort_values('gr_liv_area',ascending=False), annot = True, cmap = 'coolwarm');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f100fe",
   "metadata": {},
   "source": [
    "Some obvious relationships are: \n",
    "\n",
    "`gr_liv_area` = `1st_flr_sf` + `2nf_flr_sf` + `low_qual_fin_sf`\n",
    "\n",
    "`total_bsmt_sf` = `bsmtfin_sf_1` + `bsmtfin_sf_2` + `bsmt_unf_sf`\n",
    "\n",
    "Since `gr_liv_area` has a higher correlation to the saleprice than its components we will use `gr_liv_area` and drop the features on the RHS of the equation. The same applies to `total_bsmt_sf`.\n",
    "\n",
    "This leaves us with:\n",
    "\n",
    "- `gr_liv_area`\n",
    "- `total_bsmt_sf`\n",
    "- `garage_area`\n",
    "- `mas_vnr_area`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4d6c0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data = train_clean, x_vars = ['gr_liv_area', 'total_bsmt_sf', 'garage_area', 'mas_vnr_area'], y_vars = 'saleprice', kind = 'reg', height = 4, markers = 'x');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7c6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_select = ['gr_liv_area', 'total_bsmt_sf', 'garage_area','mas_vnr_area']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab585b2e",
   "metadata": {},
   "source": [
    "<a id='disc'></a>\n",
    "## Discrete Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dabb3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e58e2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap showing correlations between all features\n",
    "plt.figure(figsize=(15,15))\n",
    "data = train_clean[disc_features + ['saleprice']]\n",
    "mask = np.triu(data.corr())\n",
    "sns.heatmap(data.corr(), annot = True, cmap = 'coolwarm', mask = mask);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49bc19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "data = train_clean[disc_features + ['saleprice']]\n",
    "#mask = np.triu(data.corr())\n",
    "sns.heatmap(data.corr()[['saleprice']].sort_values('saleprice',ascending=False), annot = True, cmap = 'coolwarm');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c317b0d1",
   "metadata": {},
   "source": [
    "Features that show strong correlation to one another include:\n",
    "- `garage_cars`\n",
    "- `year_built`\n",
    "- `year_remod_add`\n",
    "- `garage_yr_blt`\n",
    "- `full_bath`\n",
    "- `totrms_abvgrd`\n",
    "\n",
    "Several of these features can be engineered in improve their predictive value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b116186",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672c0c50",
   "metadata": {},
   "source": [
    "#### Property Age\n",
    "`year_built` can be changed to age of property by subtracting the value from the year in which the study was conducted (2010)\n",
    "`garage_yr_blt` can be engineered into age in  similar fashion\n",
    "\n",
    "#### Years since last renovation\n",
    "`year_remod_add` can be changed to the time since the property was last renovated by subtracting its value from 2010.\n",
    "\n",
    "#### Number of baths\n",
    "A new feature `tot_baths` can be engineered by adding the `full_bath` + `bsmt_full_bath` + 0.5*(`half_bath` + `bsmt_half_bath`)\n",
    "\n",
    "#### Month sold\n",
    "Currently, the `mo_sold` is not a useful feature as the months are repeated each year. A new nominal feature, `season`, can be engineered and perhaps may give more useful insight into how sale price varies with seasonal changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11a681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "engi_features = ['year_built','garage_yr_blt','year_remod_add','full_bath', 'bsmt_full_bath', 'half_bath', 'bsmt_half_bath','mo_sold']\n",
    "features_to_engineer=train_clean[engi_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be49c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fd27b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_engineer['age'] = 2010 - features_to_engineer['year_built']\n",
    "features_to_engineer['since_reno'] = 2010 - features_to_engineer['year_remod_add']\n",
    "features_to_engineer['garage_age'] = 2010 - features_to_engineer['garage_yr_blt']\n",
    "features_to_engineer['tot_baths'] = features_to_engineer['full_bath'] + features_to_engineer['bsmt_full_bath'] + 0.5*(features_to_engineer['half_bath'] + features_to_engineer['bsmt_half_bath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7408b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_dict = {'Spring': [2,3,4],\n",
    "                'Summer' : [5,6,7],\n",
    "                'Autumn' : [8,9,10],\n",
    "                'Winter' : [11,12,1]}\n",
    "features_to_engineer['season'] = features_to_engineer['mo_sold'].map(lambda x: [i for i in seasons_dict if x in seasons_dict[i]][0])\n",
    "seasons = features_to_engineer['season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5688b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e712e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#remove the original features\n",
    "features_to_engineer.drop(columns = engi_features, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98894ed6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_to_engineer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb356e34",
   "metadata": {},
   "source": [
    "Now combining the newly engineered features to the dataset to compare its relationship with saleprice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ae2e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean_1 = pd.concat([train_clean, features_to_engineer], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002544c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "data = train_clean_1[list(features_to_engineer.columns)+ disc_features + ['saleprice']]\n",
    "mask = np.triu(data.corr())\n",
    "sns.heatmap(data.corr(), annot = True, cmap = 'coolwarm', mask = mask);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f3fd5e",
   "metadata": {},
   "source": [
    "### Discrete features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4d0613",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "data = train_clean_1[list(features_to_engineer.columns)+ disc_features + ['saleprice']]\n",
    "#mask = np.triu(data.corr())\n",
    "sns.heatmap(data.corr()[['saleprice']].sort_values('saleprice',ascending=False), annot = True, cmap = 'coolwarm');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdc825c",
   "metadata": {},
   "source": [
    "We observe an improvement in correlation of `tot_baths` to saleprice as compared to its components. Also, the features which were converted to age did not change in magnitude but became negative. Therefore it is inconsequential to perform this particular manipulation. However since it makes more sense to use  `age` rather than the `year_built`, we will use the manipulated feature instead.\n",
    "\n",
    "`age` shows a strong correlation (r = 0.85) to `garage_age` and is likely that the features are collinear. Most houses will be built around the same time as their garage, unless the garage does not exist.\n",
    "\n",
    "I also decided to drop `totrms_abvgrd` and `garage_cars` as after several iterations of linear regression modeling, the lasso coefficient for the features alwas tended to 0. This shows that there is little or no linear relationship to saleprice, meaning that these features did not add any predictive value to the model.\n",
    "\n",
    "I ended up not selecting any of the original discrete features. Instead I used the following engineered features.\n",
    "\n",
    "Engineered features:\n",
    "\n",
    "- `tot_baths`\n",
    "- `age`\n",
    "- `since_reno`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6495607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_select = ['garage_cars', 'totrms_abvgrd']\n",
    "engi_select = engi_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c5a4a5",
   "metadata": {},
   "source": [
    "<a id='ordi'></a>\n",
    "## Ordinal Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7593bc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordi_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f5831d",
   "metadata": {},
   "source": [
    "Ordinal features are categorical features where the values are associated with a ranking. Apart from `overall_qual` and `overall_cond`, most of the ordinal features are string datatypes and must be encoded to a numerical value associated with their ranking. The dictionary below establishes the order and value associated with the different categories for each ordinal feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6771bc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dictionary to map all ordinal variables, including values not present in training set. \n",
    "#A value of 0 is usually assigned to values associated with the typical/standard quality. \n",
    "#Otherwise 0 is assigned to having 'None' quality of the feature\n",
    "\n",
    "ordinal_dict = {'lot_shape': {'Reg':0, 'IR1':1, 'IR2':2, 'IR3':3}, #mapping lot_shape. Ranking represents measure of irregularity\n",
    "               \n",
    "               'utilities': {'AllPub':0, 'NoSewr':1, 'NoSeWa':2, 'ELO':3}, #mapping utilities. Ranking is based on 0 = having all public utilities, 3 = minimum utilities(electricity only) indicating a reduction in quality of life.\n",
    "               \n",
    "               'land_slope': {'Gtl':0, 'Mod':1, 'Sev':2}, #mapping land_slope. Ranking is based on slope severity.\n",
    "                \n",
    "               'exter_qual': {'Po':-4, 'Fa':-2, 'TA':0, 'Gd':2, 'Ex':4}, #mapping exter_qual, kitchen_qual, exter_cond and heating_qc\n",
    "               'kitchen_qual':{'Po':-4, 'Fa':-2, 'TA':0, 'Gd':2, 'Ex':4}, #these 4 variables take a similar ranking where 0 represents typical/average quality\n",
    "               'exter_cond': {'Po':-4, 'Fa':-2, 'TA':0, 'Gd':2, 'Ex':4}, #-ve values indicate quality below average and +ve values indicate quality above average\n",
    "               'heating_qc': {'Po':-4, 'Fa':-2, 'TA':0, 'Gd':2, 'Ex':4}, #magnitude is set as 2 to amplify effects of 'good' and 'fair' quality\n",
    "                \n",
    "               'pool_qc': {'None':0, 'Fa':1, 'TA':2, 'Gd':3, 'Ex':4}, #mapping pool_qc, bsmt_qual, bsmt_cond, fireplace_qu, garage_qual, garage_cond\n",
    "               'bsmt_qual': {'None':0, 'Po':1,'Fa':2,'TA':3, 'Gd':4, 'Ex':5}, #these variables also take a similar ranking\n",
    "               'bsmt_cond': {'None':0, 'Po':1,'Fa':2,'TA':3, 'Gd':4, 'Ex':5}, # 0 represents having no pool/basement/fireplace/garage\n",
    "               'fireplace_qu': {'None':0, 'Po':1,'Fa':2,'TA':3, 'Gd':4, 'Ex':5}, #ranking is in increasing order of quality\n",
    "               'garage_qual': {'None':0, 'Po':1,'Fa':2,'TA':3, 'Gd':4, 'Ex':5},\n",
    "               'garage_cond': {'None':0, 'Po':1,'Fa':2,'TA':3, 'Gd':4, 'Ex':5},\n",
    "                \n",
    "               'bsmt_exposure': {'No':0, 'None':0, 'Mn':1, 'Av':2, 'Gd':3}, #mapping bsmt_exposure. Having no basement and no exposure are considered to be of the same value of 0.\n",
    "                \n",
    "               'bsmtfin_type_1': {'None':0, 'Unf':1,'LwQ':2, 'Rec':3, 'BLQ':4, 'ALQ':5, 'GLQ':6}, #mapping bsmtfin_type_1 bsmtfin_type_2\n",
    "               'bsmtfin_type_2': {'None':0, 'Unf':1,'LwQ':2, 'Rec':3, 'BLQ':4, 'ALQ':5, 'GLQ':6}, #Ranking is based on quality of finish\n",
    "                \n",
    "               'electrical': {'SBrkr':0, 'FuseA':1, 'FuseF':2, 'FuseP':3, 'Mix':2.5}, #mapping electrical. Ranking is based on 0 having standard circuit breakers in in order of decreasing electrical system sophistication. \n",
    "                #Mixed electrical system is considered to be between FuseF and FuseP\n",
    "                \n",
    "               'functional':{'Typ':0,'Min1':1,'Min2':2, 'Mod':3, 'Maj1':4, 'Maj2':5, 'Sev':6, 'Sal':7}, #mapping functional. Ranking is based on 0 having typical home functionality and in decreasing order of functionality\n",
    "                \n",
    "               'garage_finish':{'None':0, 'Unf':1, 'RFn':2, 'Fin':3}, #mapping garage_finish. 0 represents having no garage and ranking is in order of quality of finish.\n",
    "                \n",
    "               'paved_drive':{'N':0, 'P':1, 'Y':2}, #mapping paved_drive. Ranking is in order of amount of paving on driveway.\n",
    "                \n",
    "               'fence':{'None':0, 'MnWw':1, 'GdWo':2, 'MnPrv':3, 'GdPrv':4} #mapping fence. 0 represents having no fence and ranking is in increasing levels of privacy\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c15c103",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping all ordinal features accordingly\n",
    "for i in ordinal_dict:\n",
    "    train_clean[i] = train_clean[i].map(ordinal_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52be17e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean[ordi_features].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bc9174",
   "metadata": {},
   "source": [
    "### Ordinal Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62118cb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "data = train_clean[ordi_features + ['saleprice']]\n",
    "mask = np.triu(data.corr())\n",
    "sns.heatmap(data.corr(), annot = True, cmap = 'coolwarm', mask = mask);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afca08c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zoom in on sale price\n",
    "plt.figure(figsize=(15,15))\n",
    "data = train_clean[ordi_features + ['saleprice']]\n",
    "sns.heatmap(data.corr()[['saleprice']].sort_values('saleprice',ascending=False), annot = True, cmap = 'coolwarm');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a4eed6",
   "metadata": {},
   "source": [
    "We want to focus on the features with strongest correlation to saleprice (corr > 0.5). These are:\n",
    "\n",
    "- `overall_qual`\n",
    "- `exter_qual`\n",
    "- `kitchen_qual`\n",
    "- `bsmt_qual`\n",
    "- `garage_finish`\n",
    "- `fireplace_qu`\n",
    "\n",
    "These features indicate the strongest linear relationship to the target variable. However we also note that `overall_qual` is strongly correlated to some of the above features. In the figure below we zoom in on the column for `overall_qual` from the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3d80a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "data = train_clean[ordi_features + ['saleprice']]\n",
    "sns.heatmap(data.corr()[['overall_qual']].sort_values('overall_qual',ascending=False), annot = True, cmap = 'coolwarm');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f129ea7f",
   "metadata": {},
   "source": [
    "Take note that the features which are strongly correlated to `overall_qual` in descending order are:\n",
    "\n",
    "- `exter_qual`\n",
    "- `kitchen_qual`\n",
    "- `bsmt_qual`\n",
    "- `garage_finish`\n",
    "\n",
    "This makes sense as these indicators are subsets of the overall quality of the house. We can drop these features from consideration and just use `overall_qual` to avoid overfitting, and consider the dropped features as components which make up the overall quality rating. \n",
    "\n",
    "This leaves us with\n",
    "\n",
    "- `overall_qual`\n",
    "- `fireplace_qu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1949970",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordi_select = ['overall_qual','fireplace_qu']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95103b82",
   "metadata": {},
   "source": [
    "<a id='nomi'></a>\n",
    "## Nominal Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaa7b01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nomi_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69db271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_count(df, list_of_titles,size):\n",
    "    nrows = int(np.ceil(len(list_of_titles)/2)) # Makes sure you have enough rows\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=2, figsize=size) # You'll want to specify your figsize\n",
    "    ax = ax.ravel()\n",
    "    for i, column_x in enumerate(df):                  # Gives us an index and columns\n",
    "        sns.countplot(data=df,\n",
    "                    x = column_x,\n",
    "                    ax= ax[i])       # Plotting diagrams\n",
    "        \n",
    "        \n",
    "    if len(list_of_titles) % 2 == 1:                             # Turn off odd number of subplots\n",
    "        ax[-1].axis('off')\n",
    "    sns.set(font_scale=1.5)    # Set scale for plots\n",
    "    plt.tight_layout()         # Move the plots so they don't overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bf05af",
   "metadata": {},
   "source": [
    "There are several nominal features with different categories for each. It might be overly complicated to inlude each dummy columns to represent each category per feature. To narrow down our selected features, we eliminate features that are heavily skewed to one category as it would not provide much predictive value. To visualize this, we can plot a countplot of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8991d38a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "subplot_count(df = train_clean[nomi_features],\n",
    "           list_of_titles = nomi_features,\n",
    "           size = (15,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a8ed4c",
   "metadata": {},
   "source": [
    "Clearly there are many features that *heavily favour one category*. We can eliminate those by *setting a threshold of 75% proportion of the majority category*. This will eliminate features that have over 75% data entries for a single category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dfd71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to select nominal features based on the spread of the data between its respective categories\n",
    "\n",
    "def select_nominal(df, features, threshold):\n",
    "    result = []\n",
    "    for i , v in enumerate(features):\n",
    "        count = df[v].value_counts()\n",
    "        weight = count[0]/count.sum()\n",
    "        if weight < threshold:\n",
    "            result.append(v)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9f4f58",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "choose_nomi = select_nominal(train_clean, nomi_features, threshold = 0.75)\n",
    "nomi_filter = train_clean[choose_nomi]\n",
    "nomi_filter = pd.concat([nomi_filter, seasons], axis = 1)\n",
    "nomi_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a102e18",
   "metadata": {},
   "source": [
    "Out of 23 features, 13 were eliminated in the process. This leaves us with 10 to explore further.\n",
    "\n",
    "For the remaining features, we can visualize the effect of each category on the target using boxplots. For the feature to hold good predictive power, there must be a clear distinction in the range of saleprices covered by the boxplot. *There should be little or no overlap between the interquartile range of the plots*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4e60e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_box(df, list_of_titles,size):\n",
    "    nrows = int(np.ceil((len(list_of_titles)-1)/2)) # Makes sure you have enough rows\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=2, figsize=size) # You'll want to specify your figsize\n",
    "    ax = ax.ravel()\n",
    "    for i, column_x in enumerate(df):# Gives us an index and columns\n",
    "        \n",
    "        if column_x != 'saleprice':\n",
    "            by_med = df[[column_x,'saleprice']].groupby(column_x).median().sort_values(by = 'saleprice').index\n",
    "            sns.boxplot(data=df,\n",
    "                        x = 'saleprice',\n",
    "                        y = column_x,\n",
    "                        orient = 'h',\n",
    "                        fliersize = 3,\n",
    "                        order = by_med,\n",
    "                        ax= ax[i])       # Plotting diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c7748c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nomi_check = pd.concat([nomi_filter, train_clean['saleprice']], axis = 1)\n",
    "subplot_box(nomi_check, \n",
    "           list(nomi_check.columns),\n",
    "           size = (20,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a850410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(nomi_check.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94210610",
   "metadata": {},
   "source": [
    "Some of the nominal features show a clear binary discintion between categories. Note that the engineered feature `season` was included in this analysis and there seems to be no clear distinction between categories for that feature. We drop the feature from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e2761",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nomi_check[['neighborhood','saleprice']].groupby('neighborhood').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37f3906",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(train_clean['saleprice']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815e94d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.log(train_clean['saleprice']).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ad5967",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sale = train_clean[['neighborhood','saleprice']]\n",
    "log_sale['log_saleprice'] = np.log(log_sale['saleprice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2ae5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7178da9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_sale[['neighborhood','log_saleprice']].groupby('neighborhood').median().sort_values(by = 'log_saleprice')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7992374",
   "metadata": {},
   "source": [
    "We divide `neighborhood` into 3 categories distinguished by their median sale prices. Note that saleprice does not follow a normal distribution, and a log transformation is applied to the saleprice before calculating the mean and standard deviation of the log saleprice. The neighborhoods are classified based on whether their median log sale price is within 1 standard deviation away from the global mean log sale price. Since 1 standard deviation from the mean represents 34.1% of all the data, removing the middle portion of the data results in a more or less \"equal\" split of the data with approximately 33% belonging to the lower and upper class neighborhoods and the remaining 34% in the middle class neighborhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2491bdc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.log(train_clean['saleprice']).mean() + np.log(train_clean['saleprice']).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38be6e14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.log(train_clean['saleprice']).mean() - np.log(train_clean['saleprice']).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ee6510",
   "metadata": {},
   "source": [
    "We can see a clear split between neighborhoods. The neighborhoods belonging to the 'upper class' will be represented by a new dummy variable `neighborhood_h` and includes:\n",
    "- `StoneBr`\n",
    "- `NridgHt`\n",
    "- `NoRidge`\n",
    "- `GrnHill`\n",
    "- `Veenker`\n",
    "\n",
    "For the lower classes, the dummmy variable created is `neighborhood_l` and it encompasses:\n",
    "- `BrDale`\n",
    "- `IDOTRR`\n",
    "- `MeadowV`\n",
    "\n",
    "\n",
    "All other remaining neighborhoods belong in the middle class therefore there isn't a need to create a third dummy column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4537c929",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nomi_check[['garage_type','saleprice']].groupby('garage_type').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5d039c",
   "metadata": {},
   "source": [
    "There are 2 groups of `garage_type`.  `Attchd` and `Builtin` for `garage_type` tends to fetch a higher saleprice than the other garage types. We can create a new feature to represent the group together `Attchd` and `Builtin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b051417",
   "metadata": {},
   "outputs": [],
   "source": [
    "nomi_select = ['neighborhood','garage_type']\n",
    "engi_features_2 = nomi_check[nomi_select]\n",
    "engi_features_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3db532",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "engi_features_2['neighbor_h'] = engi_features_2['neighborhood'].map(lambda x: 1 if x == 'StoneBr' or x =='NridgHt' or x == 'NoRidge' or x == 'GrnHill' or x == 'Veenker' else 0)\n",
    "engi_features_2['neighbor_l'] = engi_features_2['neighborhood'].map(lambda x: 1 if x == 'BrDale' or x == 'IDOTRR' or x == 'MeadowV' else 0)\n",
    "\n",
    "\n",
    "engi_features_2['garage_type_a'] = engi_features_2['garage_type'].map(lambda x: 1 if x == 'Attchd' or x == 'BuiltIn' else 0)\n",
    "engi_features_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fca02df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "engi_features_2.drop(columns = ['neighborhood','garage_type'], inplace = True)\n",
    "engi_features_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8e89c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([engi_features_2,train_clean['saleprice']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde32a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y = data['neighbor_h'], x = data['saleprice']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5368a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y = data['neighbor_l'], x = data['saleprice']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ee7cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y = data['garage_type_a'], x = data['saleprice']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fc8763",
   "metadata": {},
   "source": [
    "There looks to be slight distinction between the groups for the new binary variables. More noticably in `neighbor_h` and `neighbor_l`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90372772",
   "metadata": {},
   "source": [
    "<a id='poly'></a>\n",
    "## Polynomial Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd7dbb2",
   "metadata": {},
   "source": [
    "To minimize the complexity with computing polynomial features over the entire dataset, we instead perform the analysis on the selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826c9438",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features = cont_select + disc_select + ordi_select + nomi_select + engi_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e22cc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaa7072",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = train_clean[model_features]\n",
    "\n",
    "\n",
    "#Discrete feature engineering\n",
    "model_df['age'] = 2010 - model_df['year_built']\n",
    "model_df['since_reno'] = 2010 - model_df['year_remod_add']\n",
    "model_df['tot_baths'] = model_df['full_bath'] + model_df['bsmt_full_bath'] + 0.5*(model_df['half_bath'] + model_df['bsmt_half_bath'])\n",
    "\n",
    "#Drop the original columns\n",
    "model_df.drop(columns = engi_select, inplace = True)\n",
    "\n",
    "#Ordinal features already mapped for train set\n",
    "\n",
    "#Nominal features mapping\n",
    "model_df['neighbor_h'] = model_df['neighborhood'].map(lambda x: 1 if x == 'StoneBr' or x =='NridgHt' or x == 'NoRidge' or x == 'GrnHill' else 0)\n",
    "model_df['neighbor_l'] = model_df['neighborhood'].map(lambda x: 1 if x == 'Sawyer' or x == 'Names' or x == 'Edwards' or x == 'OldTown'\n",
    "                                                                    or x == 'BrDale' or x == 'IDOTRR' or x == 'MeadowV' or x == 'BrkSide' \n",
    "                                                                    or x == 'NPkVill' or x == 'Blueste' or x == 'SWISU' else 0)\n",
    "model_df['garage_type_a'] = model_df['garage_type'].map(lambda x: 1 if x == 'Attchd' or x == 'BuiltIn' else 0)\n",
    "\n",
    "#Drop the original columns\n",
    "model_df.drop(columns = nomi_select, inplace = True)\n",
    "\n",
    "#Display the resulting model features\n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b227206",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(include_bias=False)\n",
    "X_pol = poly.fit_transform(model_df)\n",
    "X_pol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e5c2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pol = pd.DataFrame(X_pol,columns=poly.get_feature_names(model_df.columns))\n",
    "\n",
    "#create list of correlations between features with price\n",
    "X_pol_corrs = X_pol.corrwith(train_clean[target])\n",
    "\n",
    "#Shows features with highest positive correlation to price\n",
    "X_pol_corrs.sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c21f401",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pol['saleprice'] = train_clean['saleprice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab32b97f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data = X_pol, y_vars = 'saleprice', x_vars = ['gr_liv_area','gr_liv_area overall_qual','overall_qual'], height = 5, kind = 'reg');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d7b27b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data = X_pol, y_vars = 'saleprice', x_vars = ['total_bsmt_sf','total_bsmt_sf overall_qual','overall_qual'], height = 5, kind = 'reg');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce3a6de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data = X_pol, y_vars = 'saleprice', x_vars = ['garage_area','garage_area overall_qual','overall_qual'], height = 5, kind = 'reg');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b011169d",
   "metadata": {},
   "source": [
    "We can see that the polynomial features can improve the predictive power of our original features. Some of the polynomial features show higher correlation with the sale price than the original features. From the above scatter plots, we can see that the polynomial features help to centre the datapoints closer to the regression line. However most of these polynomial features are collinear. After several model iterations using different combinations of polynomial features, I ended up using `gr_liv_area overall_qual` and `garage_area overall_qual`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46b9583",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df['gr_liv_area overall_qual'] = X_pol['gr_liv_area overall_qual']\n",
    "model_df['garage_area overall_qual'] = X_pol['garage_area overall_qual']\n",
    "\n",
    "#drop the unnecessary disc features\n",
    "model_df.drop(columns =['garage_cars','totrms_abvgrd'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40f1c66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00950f51",
   "metadata": {},
   "source": [
    "<a id='target'></a>\n",
    "## Target Feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a5489e",
   "metadata": {},
   "source": [
    "The target feature, saleprice is continuous and we would expect it to follow a normal distribution over a large sample size. Plotting the distribution of the saleprice from the training dataset, we can see evidence of positive skewness. This means that the data is concentrated on the lower range of saleprices. The median and mode of the data is less than its mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2784c138",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "sns.histplot(data = train_clean,\n",
    "            x = 'saleprice');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fd2603",
   "metadata": {},
   "source": [
    "Skewness in the target variable can lead to inaccurate predictions such as underestimating saleprices. We can perform feature engineering on the target feature to normalize its distribution and reduce skewness. A common technique is to perform **logarithmic transformation of the target feature**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46cd8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log = np.log(train_clean['saleprice'])\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.histplot(y_log);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2912f9",
   "metadata": {},
   "source": [
    "This is the final transformation to apply to the train dataset. After making predictions, the values of **predicted saleprice need to be exponentiated** to convert them back to their actual sale prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61732f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df['saleprice'] = train_clean['saleprice']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7d1425",
   "metadata": {},
   "source": [
    "<a id='select'></a>\n",
    "## Features selected for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfc9703",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fd8da4",
   "metadata": {},
   "source": [
    "There are a total of 14 features selected for our model. We will export this dataframe to be used in our modelling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fccd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.to_csv('./datasets/train_model_features.csv', index = False)\n",
    "\n",
    "#save a copy of our original cleaned data\n",
    "train_clean.to_csv('./datasets/train_clean.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3548b31c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
